{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Topic modeling\n",
    "\n",
    "| Student Name         | Student-ID |\n",
    "|----------------------|------------|\n",
    "| Marco Di Francesco   | 100632815  |\n",
    "| Loreto García Tejada | 100643862  |\n",
    "| György Bence Józsa   | 100633270  |\n",
    "| József-Hunor Jánosi  | 100516724  |\n",
    "| Sara-Jane Bittner    | 100498554  |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Learning goal: Processing text data, converting it into a numerical format and performing topic analysis using SVD._\n",
    "\n",
    "To complete the assignment you are allowed to use the NLTK natural language toolkit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "a) Load _applications_of_DM.csv_, e.g. with `pandas` in Python. It has titles and text content of Wikipedia articles on data mining. In the following tasks, you are to work with the \"tex\"-attribute."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                title  \\\n0                Anomaly Detection at Multiple Scales   \n1                                Behavioral analytics   \n2                                  Business analytics   \n3                             CORE (research service)   \n4                                  Daisy Intelligence   \n5                                        Data Applied   \n6                          Data mining in agriculture   \n7                                       Data thinking   \n8                                 Document processing   \n9                         Equifax Workforce Solutions   \n10                                     Game analytics   \n11                                   Inference attack   \n12                          Path analysis (computing)   \n13  Automatic number-plate recognition in the Unit...   \n14                         PRODIGAL (computer system)   \n15                                        Text mining   \n16                                            Zapaday   \n\n                                                 text  \n0   Anomaly Detection at Multiple Scales, or ADAMS...  \n1   Behaviorism is a systematic approach to unders...  \n2   Business analysis is a professional discipline...  \n3   CORE (Connecting Repositories) is a service pr...  \n4   Daisy Intelligence is a Canadian Artificial In...  \n5   Data Applied is a software vendor headquartere...  \n6   Data mining in agriculture is a recent researc...  \n7   Data thinking is a buzzword for the generic \"m...  \n8   Document processing is a field of research and...  \n9   Equifax Workforce Solutions, formerly known as...  \n10  Game analytics is the form of behavioral analy...  \n11  An Inference Attack is a data mining technique...  \n12  Path analysis, is the analysis of a path, whic...  \n13  Automatic number-plate recognition (ANPR; see ...  \n14  PRODIGAL (proactive discovery of insider threa...  \n15  Text mining, also referred to as text data min...  \n16  Zapaday is a global news calendar. The website...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anomaly Detection at Multiple Scales</td>\n      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Behavioral analytics</td>\n      <td>Behaviorism is a systematic approach to unders...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Business analytics</td>\n      <td>Business analysis is a professional discipline...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CORE (research service)</td>\n      <td>CORE (Connecting Repositories) is a service pr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daisy Intelligence</td>\n      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Applied</td>\n      <td>Data Applied is a software vendor headquartere...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Data mining in agriculture</td>\n      <td>Data mining in agriculture is a recent researc...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Data thinking</td>\n      <td>Data thinking is a buzzword for the generic \"m...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Document processing</td>\n      <td>Document processing is a field of research and...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Equifax Workforce Solutions</td>\n      <td>Equifax Workforce Solutions, formerly known as...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Game analytics</td>\n      <td>Game analytics is the form of behavioral analy...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Inference attack</td>\n      <td>An Inference Attack is a data mining technique...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Path analysis (computing)</td>\n      <td>Path analysis, is the analysis of a path, whic...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Automatic number-plate recognition in the Unit...</td>\n      <td>Automatic number-plate recognition (ANPR; see ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PRODIGAL (computer system)</td>\n      <td>PRODIGAL (proactive discovery of insider threa...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Text mining</td>\n      <td>Text mining, also referred to as text data min...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Zapaday</td>\n      <td>Zapaday is a global news calendar. The website...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('applications_of_DM.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "b) Process and tokenize the text data: lowercase all words, remove digits, punctuation, any special characters and NLTK’s common English stopwords. List $10$ most frequent $n$-grams, $n = 1, 2, 3,$ and their raw counts. Then, convert $1700$ most frequent $n$-grams, across all $n$-values, into numerical matrices, i.e., features $X_\\mathrm{raw},X_\\mathrm{tf-idf} \\in \\mathbb{R}^{docs \\times terms}$. Features $X_\\mathrm{raw}$ are raw $n$-gram counts, $X_\\mathrm{tf-idf}$ are tf-idf values (see the specific format below)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) Using SVD, decompose and truncate your numerical features $X = U \\Sigma V^\\top$ into ($docs \\times topics$) and ($topics \\times terms$) matrices (left/right singular vectors, respectively) using $6$ topics. List $5$ most significant $n$-grams for each topic, measured by values of the ($topics \\times terms$) matrix. Do this for both features $X_\\mathrm{raw}$ and $X_\\mathrm{tf-idf}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "d) Compare and comment the results with respect to the selection of features and the $n$ value in $n$-grams."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The format of tf-idf you need to use:**\n",
    "\n",
    "$$ f(tf, idf) = (1 + \\ln (tf)) \\cdot idf $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ tf = \\frac{number\\ of\\ times\\ term\\ w\\ appears\\ in\\ a\\ document}{total\\ number\\ of\\ terms\\ in\\ that\\ document} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ idf = \\ln(\\frac{total\\ number\\ of\\ documents}{number\\ of\\ documents\\ with\\ term\\ w\\ in\\ them + 1} + 1) $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}