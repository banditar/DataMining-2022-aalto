{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Topic modeling\n",
    "\n",
    "| Student Name         | Student-ID |\n",
    "|----------------------|------------|\n",
    "| Marco Di Francesco   | 100632815  |\n",
    "| Loreto García Tejada | 100643862  |\n",
    "| György Bence Józsa   | 100633270  |\n",
    "| József-Hunor Jánosi  | 100516724  |\n",
    "| Sara-Jane Bittner    | 100498554  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "_Learning goal: Processing text data, converting it into a numerical format and performing topic analysis using SVD._\n",
    "\n",
    "To complete the assignment you are allowed to use the NLTK natural language toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from typing import Union, Tuple, Dict, List\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sara-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) Load _applications_of_DM.csv_, e.g. with `pandas` in Python. It has titles and text content of Wikipedia articles on data mining. In the following tasks, you are to work with the \"tex\"-attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anomaly Detection at Multiple Scales</td>\n",
       "      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behavioral analytics</td>\n",
       "      <td>Behaviorism is a systematic approach to unders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business analytics</td>\n",
       "      <td>Business analysis is a professional discipline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORE (research service)</td>\n",
       "      <td>CORE (Connecting Repositories) is a service pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daisy Intelligence</td>\n",
       "      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Applied</td>\n",
       "      <td>Data Applied is a software vendor headquartere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data mining in agriculture</td>\n",
       "      <td>Data mining in agriculture is a recent researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data thinking</td>\n",
       "      <td>Data thinking is a buzzword for the generic \"m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Document processing</td>\n",
       "      <td>Document processing is a field of research and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Equifax Workforce Solutions</td>\n",
       "      <td>Equifax Workforce Solutions, formerly known as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Game analytics</td>\n",
       "      <td>Game analytics is the form of behavioral analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Inference attack</td>\n",
       "      <td>An Inference Attack is a data mining technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Path analysis (computing)</td>\n",
       "      <td>Path analysis, is the analysis of a path, whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Automatic number-plate recognition in the Unit...</td>\n",
       "      <td>Automatic number-plate recognition (ANPR; see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRODIGAL (computer system)</td>\n",
       "      <td>PRODIGAL (proactive discovery of insider threa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Text mining</td>\n",
       "      <td>Text mining, also referred to as text data min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zapaday</td>\n",
       "      <td>Zapaday is a global news calendar. The website...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                Anomaly Detection at Multiple Scales   \n",
       "1                                Behavioral analytics   \n",
       "2                                  Business analytics   \n",
       "3                             CORE (research service)   \n",
       "4                                  Daisy Intelligence   \n",
       "5                                        Data Applied   \n",
       "6                          Data mining in agriculture   \n",
       "7                                       Data thinking   \n",
       "8                                 Document processing   \n",
       "9                         Equifax Workforce Solutions   \n",
       "10                                     Game analytics   \n",
       "11                                   Inference attack   \n",
       "12                          Path analysis (computing)   \n",
       "13  Automatic number-plate recognition in the Unit...   \n",
       "14                         PRODIGAL (computer system)   \n",
       "15                                        Text mining   \n",
       "16                                            Zapaday   \n",
       "\n",
       "                                                 text  \n",
       "0   Anomaly Detection at Multiple Scales, or ADAMS...  \n",
       "1   Behaviorism is a systematic approach to unders...  \n",
       "2   Business analysis is a professional discipline...  \n",
       "3   CORE (Connecting Repositories) is a service pr...  \n",
       "4   Daisy Intelligence is a Canadian Artificial In...  \n",
       "5   Data Applied is a software vendor headquartere...  \n",
       "6   Data mining in agriculture is a recent researc...  \n",
       "7   Data thinking is a buzzword for the generic \"m...  \n",
       "8   Document processing is a field of research and...  \n",
       "9   Equifax Workforce Solutions, formerly known as...  \n",
       "10  Game analytics is the form of behavioral analy...  \n",
       "11  An Inference Attack is a data mining technique...  \n",
       "12  Path analysis, is the analysis of a path, whic...  \n",
       "13  Automatic number-plate recognition (ANPR; see ...  \n",
       "14  PRODIGAL (proactive discovery of insider threa...  \n",
       "15  Text mining, also referred to as text data min...  \n",
       "16  Zapaday is a global news calendar. The website...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('applications_of_DM.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "b) Process and tokenize the text data: lowercase all words, remove digits, punctuation, any special characters and NLTK’s common English stopwords. List $10$ most frequent $n$-grams, $n = 1, 2, 3,$ and their raw counts. Then, convert $1700$ most frequent $n$-grams, across all $n$-values, into numerical matrices, i.e., features $X_\\mathrm{raw},X_\\mathrm{tf-idf} \\in \\mathbb{R}^{docs \\times terms}$. Features $X_\\mathrm{raw}$ are raw $n$-gram counts, $X_\\mathrm{tf-idf}$ are tf-idf values (see the specific format below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_text(text: str) -> list[str]:\n",
    "    \"\"\"Removes special characters and numbers from a given text and returns a list of words of that text in lower case, removing common english stopwords.\n",
    "\n",
    "    :param text: the raw text to be processed\n",
    "    :return: a list of words in the original text with no special characters, numbers and common english stopwords in lower case.\n",
    "    \"\"\"\n",
    "    # remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())\n",
    "    words = text.split()\n",
    "    # filter out common english stopwords and return list\n",
    "    return [word for word in words if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anomaly Detection at Multiple Scales</td>\n",
       "      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n",
       "      <td>[anomaly, detection, multiple, scales, adams, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behavioral analytics</td>\n",
       "      <td>Behaviorism is a systematic approach to unders...</td>\n",
       "      <td>[behaviorism, systematic, approach, understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business analytics</td>\n",
       "      <td>Business analysis is a professional discipline...</td>\n",
       "      <td>[business, analysis, professional, discipline,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORE (research service)</td>\n",
       "      <td>CORE (Connecting Repositories) is a service pr...</td>\n",
       "      <td>[core, connecting, repositories, service, prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daisy Intelligence</td>\n",
       "      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n",
       "      <td>[daisy, intelligence, canadian, artificial, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Applied</td>\n",
       "      <td>Data Applied is a software vendor headquartere...</td>\n",
       "      <td>[data, applied, software, vendor, headquartere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data mining in agriculture</td>\n",
       "      <td>Data mining in agriculture is a recent researc...</td>\n",
       "      <td>[data, mining, agriculture, recent, research, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data thinking</td>\n",
       "      <td>Data thinking is a buzzword for the generic \"m...</td>\n",
       "      <td>[data, thinking, buzzword, generic, mental, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Document processing</td>\n",
       "      <td>Document processing is a field of research and...</td>\n",
       "      <td>[document, processing, field, research, set, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Equifax Workforce Solutions</td>\n",
       "      <td>Equifax Workforce Solutions, formerly known as...</td>\n",
       "      <td>[equifax, workforce, solutions, formerly, know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Game analytics</td>\n",
       "      <td>Game analytics is the form of behavioral analy...</td>\n",
       "      <td>[game, analytics, form, behavioral, analytics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Inference attack</td>\n",
       "      <td>An Inference Attack is a data mining technique...</td>\n",
       "      <td>[inference, attack, data, mining, technique, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Path analysis (computing)</td>\n",
       "      <td>Path analysis, is the analysis of a path, whic...</td>\n",
       "      <td>[path, analysis, analysis, path, portrayal, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Automatic number-plate recognition in the Unit...</td>\n",
       "      <td>Automatic number-plate recognition (ANPR; see ...</td>\n",
       "      <td>[automatic, number, plate, recognition, anpr, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRODIGAL (computer system)</td>\n",
       "      <td>PRODIGAL (proactive discovery of insider threa...</td>\n",
       "      <td>[prodigal, proactive, discovery, insider, thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Text mining</td>\n",
       "      <td>Text mining, also referred to as text data min...</td>\n",
       "      <td>[text, mining, also, referred, text, data, min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zapaday</td>\n",
       "      <td>Zapaday is a global news calendar. The website...</td>\n",
       "      <td>[zapaday, global, news, calendar, website, pub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                Anomaly Detection at Multiple Scales   \n",
       "1                                Behavioral analytics   \n",
       "2                                  Business analytics   \n",
       "3                             CORE (research service)   \n",
       "4                                  Daisy Intelligence   \n",
       "5                                        Data Applied   \n",
       "6                          Data mining in agriculture   \n",
       "7                                       Data thinking   \n",
       "8                                 Document processing   \n",
       "9                         Equifax Workforce Solutions   \n",
       "10                                     Game analytics   \n",
       "11                                   Inference attack   \n",
       "12                          Path analysis (computing)   \n",
       "13  Automatic number-plate recognition in the Unit...   \n",
       "14                         PRODIGAL (computer system)   \n",
       "15                                        Text mining   \n",
       "16                                            Zapaday   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Anomaly Detection at Multiple Scales, or ADAMS...   \n",
       "1   Behaviorism is a systematic approach to unders...   \n",
       "2   Business analysis is a professional discipline...   \n",
       "3   CORE (Connecting Repositories) is a service pr...   \n",
       "4   Daisy Intelligence is a Canadian Artificial In...   \n",
       "5   Data Applied is a software vendor headquartere...   \n",
       "6   Data mining in agriculture is a recent researc...   \n",
       "7   Data thinking is a buzzword for the generic \"m...   \n",
       "8   Document processing is a field of research and...   \n",
       "9   Equifax Workforce Solutions, formerly known as...   \n",
       "10  Game analytics is the form of behavioral analy...   \n",
       "11  An Inference Attack is a data mining technique...   \n",
       "12  Path analysis, is the analysis of a path, whic...   \n",
       "13  Automatic number-plate recognition (ANPR; see ...   \n",
       "14  PRODIGAL (proactive discovery of insider threa...   \n",
       "15  Text mining, also referred to as text data min...   \n",
       "16  Zapaday is a global news calendar. The website...   \n",
       "\n",
       "                                        filtered_text  \n",
       "0   [anomaly, detection, multiple, scales, adams, ...  \n",
       "1   [behaviorism, systematic, approach, understand...  \n",
       "2   [business, analysis, professional, discipline,...  \n",
       "3   [core, connecting, repositories, service, prov...  \n",
       "4   [daisy, intelligence, canadian, artificial, in...  \n",
       "5   [data, applied, software, vendor, headquartere...  \n",
       "6   [data, mining, agriculture, recent, research, ...  \n",
       "7   [data, thinking, buzzword, generic, mental, pa...  \n",
       "8   [document, processing, field, research, set, p...  \n",
       "9   [equifax, workforce, solutions, formerly, know...  \n",
       "10  [game, analytics, form, behavioral, analytics,...  \n",
       "11  [inference, attack, data, mining, technique, p...  \n",
       "12  [path, analysis, analysis, path, portrayal, ch...  \n",
       "13  [automatic, number, plate, recognition, anpr, ...  \n",
       "14  [prodigal, proactive, discovery, insider, thre...  \n",
       "15  [text, mining, also, referred, text, data, min...  \n",
       "16  [zapaday, global, news, calendar, website, pub...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_text'] = df['text'].map(process_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_ngram(corpus: list[str], n: int) -> Dict[Tuple[str, ...], int]:\n",
    "    \"\"\"Creates a frequency-list of specified n-grams in the given corpus\n",
    "\n",
    "    :param corpus: Ordered list of words in the corpus\n",
    "    :param n: number of elements in n-gram creation\n",
    "    :return: dictionary with keys being unique n-grams and values being the frequencies of them\n",
    "    \"\"\"\n",
    "    grams = list(ngrams(corpus, n))\n",
    "    return {i:grams.count(i) for i in set(grams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>unigrams</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anomaly Detection at Multiple Scales</td>\n",
       "      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n",
       "      <td>[anomaly, detection, multiple, scales, adams, ...</td>\n",
       "      <td>{('recipients',): 1, ('access',): 1, ('specifi...</td>\n",
       "      <td>{('project', 'intended'): 1, ('noted', 'high')...</td>\n",
       "      <td>{('information', 'specific', 'cases'): 1, ('ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Behavioral analytics</td>\n",
       "      <td>Behaviorism is a systematic approach to unders...</td>\n",
       "      <td>[behaviorism, systematic, approach, understand...</td>\n",
       "      <td>{('certain',): 2, ('number',): 1, ('physics',)...</td>\n",
       "      <td>{('video', 'games'): 2, ('understanding', 'cov...</td>\n",
       "      <td>{('bell', 'ring', 'number'): 1, ('viewpoint', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business analytics</td>\n",
       "      <td>Business analysis is a professional discipline...</td>\n",
       "      <td>[business, analysis, professional, discipline,...</td>\n",
       "      <td>{('incomplete',): 1, ('scheduling',): 1, ('num...</td>\n",
       "      <td>{('ongoing', 'massive'): 1, ('tasks', 'task'):...</td>\n",
       "      <td>{('storage', 'databases', 'analysis'): 1, ('es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORE (research service)</td>\n",
       "      <td>CORE (Connecting Repositories) is a service pr...</td>\n",
       "      <td>[core, connecting, repositories, service, prov...</td>\n",
       "      <td>{('along',): 1, ('kingdom',): 1, ('number',): ...</td>\n",
       "      <td>{('tool', 'uk'): 1, ('text', 'open'): 1, ('acc...</td>\n",
       "      <td>{('applications', 'making', 'use'): 1, ('knoth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daisy Intelligence</td>\n",
       "      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n",
       "      <td>[daisy, intelligence, canadian, artificial, in...</td>\n",
       "      <td>{('concentrated',): 1, ('help',): 1, ('uses',)...</td>\n",
       "      <td>{('provides', 'data'): 1, ('promotional', 'mix...</td>\n",
       "      <td>{('mail', 'annual', 'list'): 1, ('retailers', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Applied</td>\n",
       "      <td>Data Applied is a software vendor headquartere...</td>\n",
       "      <td>[data, applied, software, vendor, headquartere...</td>\n",
       "      <td>{('implements',): 1, ('vendor',): 1, ('product...</td>\n",
       "      <td>{('data', 'mining'): 2, ('tree', 'maps'): 1, (...</td>\n",
       "      <td>{('trees', 'association', 'rules'): 1, ('self'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data mining in agriculture</td>\n",
       "      <td>Data mining in agriculture is a recent researc...</td>\n",
       "      <td>[data, mining, agriculture, recent, research, ...</td>\n",
       "      <td>{('along',): 2, ('cotton',): 5, ('results',): ...</td>\n",
       "      <td>{('affect', 'longevity'): 1, ('animals', 'caus...</td>\n",
       "      <td>{('sometimes', 'insurance', 'reasons'): 1, ('a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data thinking</td>\n",
       "      <td>Data thinking is a buzzword for the generic \"m...</td>\n",
       "      <td>[data, thinking, buzzword, generic, mental, pa...</td>\n",
       "      <td>{('profitability',): 2, ('defined',): 1, ('con...</td>\n",
       "      <td>{('areas', 'successful'): 1, ('ai', 'driven'):...</td>\n",
       "      <td>{('feasibility', 'stage', 'also'): 1, ('data',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Document processing</td>\n",
       "      <td>Document processing is a field of research and...</td>\n",
       "      <td>[document, processing, field, research, set, p...</td>\n",
       "      <td>{('world',): 1, ('mechanical',): 1, ('orders',...</td>\n",
       "      <td>{('obtain', 'digital'): 1, ('massively', 'extr...</td>\n",
       "      <td>{('processing', 'involved', 'data'): 1, ('bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Equifax Workforce Solutions</td>\n",
       "      <td>Equifax Workforce Solutions, formerly known as...</td>\n",
       "      <td>[equifax, workforce, solutions, formerly, know...</td>\n",
       "      <td>{('number',): 6, ('certain',): 3, ('w',): 3, (...</td>\n",
       "      <td>{('credit', 'approvals'): 1, ('focus', 'core')...</td>\n",
       "      <td>{('auditors', 'sec', 'sought'): 1, ('ceo', 'ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Game analytics</td>\n",
       "      <td>Game analytics is the form of behavioral analy...</td>\n",
       "      <td>[game, analytics, form, behavioral, analytics,...</td>\n",
       "      <td>{('redesign',): 1, ('measures',): 1, ('form',)...</td>\n",
       "      <td>{('video', 'games'): 1, ('would', 'programming...</td>\n",
       "      <td>{('developers', 'regards', 'player'): 1, ('reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Inference attack</td>\n",
       "      <td>An Inference Attack is a data mining technique...</td>\n",
       "      <td>[inference, attack, data, mining, technique, p...</td>\n",
       "      <td>{('privacy',): 1, ('discovered',): 1, ('party'...</td>\n",
       "      <td>{('data', 'accelerometers'): 1, ('used', 'infe...</td>\n",
       "      <td>{('occurs', 'user', 'able'): 1, ('information'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Path analysis (computing)</td>\n",
       "      <td>Path analysis, is the analysis of a path, whic...</td>\n",
       "      <td>[path, analysis, analysis, path, portrayal, ch...</td>\n",
       "      <td>{('along',): 1, ('certain',): 6, ('world',): 1...</td>\n",
       "      <td>{('path', 'site'): 1, ('products', 'next'): 1,...</td>\n",
       "      <td>{('site', 'running', 'slow'): 1, ('discovery',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Automatic number-plate recognition in the Unit...</td>\n",
       "      <td>Automatic number-plate recognition (ANPR; see ...</td>\n",
       "      <td>[automatic, number, plate, recognition, anpr, ...</td>\n",
       "      <td>{('number',): 26, ('stolen',): 9, ('certain',)...</td>\n",
       "      <td>{('branch', 'britain'): 1, ('distances', 'rath...</td>\n",
       "      <td>{('senate', 'bill', 'caused'): 1, ('systems', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRODIGAL (computer system)</td>\n",
       "      <td>PRODIGAL (proactive discovery of insider threa...</td>\n",
       "      <td>[prodigal, proactive, discovery, insider, thre...</td>\n",
       "      <td>{('results',): 1, ('analysts',): 1, ('prodigal...</td>\n",
       "      <td>{('georgia', 'institute'): 1, ('international'...</td>\n",
       "      <td>{('learning', 'statistical', 'anomaly'): 1, ('...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Text mining</td>\n",
       "      <td>Text mining, also referred to as text data min...</td>\n",
       "      <td>[text, mining, also, referred, text, data, min...</td>\n",
       "      <td>{('along',): 1, ('deriving',): 2, ('certain',)...</td>\n",
       "      <td>{('role', 'determining'): 1, ('analysis', 'stu...</td>\n",
       "      <td>{('analysis', 'set', 'techniques'): 1, ('may',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zapaday</td>\n",
       "      <td>Zapaday is a global news calendar. The website...</td>\n",
       "      <td>[zapaday, global, news, calendar, website, pub...</td>\n",
       "      <td>{('analysts',): 1, ('offer',): 1, ('premium',)...</td>\n",
       "      <td>{('creator', 'zapaday'): 1, ('events', 'zapada...</td>\n",
       "      <td>{('platform', 'anp', 'agenda'): 1, ('nearly', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                Anomaly Detection at Multiple Scales   \n",
       "1                                Behavioral analytics   \n",
       "2                                  Business analytics   \n",
       "3                             CORE (research service)   \n",
       "4                                  Daisy Intelligence   \n",
       "5                                        Data Applied   \n",
       "6                          Data mining in agriculture   \n",
       "7                                       Data thinking   \n",
       "8                                 Document processing   \n",
       "9                         Equifax Workforce Solutions   \n",
       "10                                     Game analytics   \n",
       "11                                   Inference attack   \n",
       "12                          Path analysis (computing)   \n",
       "13  Automatic number-plate recognition in the Unit...   \n",
       "14                         PRODIGAL (computer system)   \n",
       "15                                        Text mining   \n",
       "16                                            Zapaday   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Anomaly Detection at Multiple Scales, or ADAMS...   \n",
       "1   Behaviorism is a systematic approach to unders...   \n",
       "2   Business analysis is a professional discipline...   \n",
       "3   CORE (Connecting Repositories) is a service pr...   \n",
       "4   Daisy Intelligence is a Canadian Artificial In...   \n",
       "5   Data Applied is a software vendor headquartere...   \n",
       "6   Data mining in agriculture is a recent researc...   \n",
       "7   Data thinking is a buzzword for the generic \"m...   \n",
       "8   Document processing is a field of research and...   \n",
       "9   Equifax Workforce Solutions, formerly known as...   \n",
       "10  Game analytics is the form of behavioral analy...   \n",
       "11  An Inference Attack is a data mining technique...   \n",
       "12  Path analysis, is the analysis of a path, whic...   \n",
       "13  Automatic number-plate recognition (ANPR; see ...   \n",
       "14  PRODIGAL (proactive discovery of insider threa...   \n",
       "15  Text mining, also referred to as text data min...   \n",
       "16  Zapaday is a global news calendar. The website...   \n",
       "\n",
       "                                        filtered_text  \\\n",
       "0   [anomaly, detection, multiple, scales, adams, ...   \n",
       "1   [behaviorism, systematic, approach, understand...   \n",
       "2   [business, analysis, professional, discipline,...   \n",
       "3   [core, connecting, repositories, service, prov...   \n",
       "4   [daisy, intelligence, canadian, artificial, in...   \n",
       "5   [data, applied, software, vendor, headquartere...   \n",
       "6   [data, mining, agriculture, recent, research, ...   \n",
       "7   [data, thinking, buzzword, generic, mental, pa...   \n",
       "8   [document, processing, field, research, set, p...   \n",
       "9   [equifax, workforce, solutions, formerly, know...   \n",
       "10  [game, analytics, form, behavioral, analytics,...   \n",
       "11  [inference, attack, data, mining, technique, p...   \n",
       "12  [path, analysis, analysis, path, portrayal, ch...   \n",
       "13  [automatic, number, plate, recognition, anpr, ...   \n",
       "14  [prodigal, proactive, discovery, insider, thre...   \n",
       "15  [text, mining, also, referred, text, data, min...   \n",
       "16  [zapaday, global, news, calendar, website, pub...   \n",
       "\n",
       "                                             unigrams  \\\n",
       "0   {('recipients',): 1, ('access',): 1, ('specifi...   \n",
       "1   {('certain',): 2, ('number',): 1, ('physics',)...   \n",
       "2   {('incomplete',): 1, ('scheduling',): 1, ('num...   \n",
       "3   {('along',): 1, ('kingdom',): 1, ('number',): ...   \n",
       "4   {('concentrated',): 1, ('help',): 1, ('uses',)...   \n",
       "5   {('implements',): 1, ('vendor',): 1, ('product...   \n",
       "6   {('along',): 2, ('cotton',): 5, ('results',): ...   \n",
       "7   {('profitability',): 2, ('defined',): 1, ('con...   \n",
       "8   {('world',): 1, ('mechanical',): 1, ('orders',...   \n",
       "9   {('number',): 6, ('certain',): 3, ('w',): 3, (...   \n",
       "10  {('redesign',): 1, ('measures',): 1, ('form',)...   \n",
       "11  {('privacy',): 1, ('discovered',): 1, ('party'...   \n",
       "12  {('along',): 1, ('certain',): 6, ('world',): 1...   \n",
       "13  {('number',): 26, ('stolen',): 9, ('certain',)...   \n",
       "14  {('results',): 1, ('analysts',): 1, ('prodigal...   \n",
       "15  {('along',): 1, ('deriving',): 2, ('certain',)...   \n",
       "16  {('analysts',): 1, ('offer',): 1, ('premium',)...   \n",
       "\n",
       "                                              bigrams  \\\n",
       "0   {('project', 'intended'): 1, ('noted', 'high')...   \n",
       "1   {('video', 'games'): 2, ('understanding', 'cov...   \n",
       "2   {('ongoing', 'massive'): 1, ('tasks', 'task'):...   \n",
       "3   {('tool', 'uk'): 1, ('text', 'open'): 1, ('acc...   \n",
       "4   {('provides', 'data'): 1, ('promotional', 'mix...   \n",
       "5   {('data', 'mining'): 2, ('tree', 'maps'): 1, (...   \n",
       "6   {('affect', 'longevity'): 1, ('animals', 'caus...   \n",
       "7   {('areas', 'successful'): 1, ('ai', 'driven'):...   \n",
       "8   {('obtain', 'digital'): 1, ('massively', 'extr...   \n",
       "9   {('credit', 'approvals'): 1, ('focus', 'core')...   \n",
       "10  {('video', 'games'): 1, ('would', 'programming...   \n",
       "11  {('data', 'accelerometers'): 1, ('used', 'infe...   \n",
       "12  {('path', 'site'): 1, ('products', 'next'): 1,...   \n",
       "13  {('branch', 'britain'): 1, ('distances', 'rath...   \n",
       "14  {('georgia', 'institute'): 1, ('international'...   \n",
       "15  {('role', 'determining'): 1, ('analysis', 'stu...   \n",
       "16  {('creator', 'zapaday'): 1, ('events', 'zapada...   \n",
       "\n",
       "                                             trigrams  \n",
       "0   {('information', 'specific', 'cases'): 1, ('ma...  \n",
       "1   {('bell', 'ring', 'number'): 1, ('viewpoint', ...  \n",
       "2   {('storage', 'databases', 'analysis'): 1, ('es...  \n",
       "3   {('applications', 'making', 'use'): 1, ('knoth...  \n",
       "4   {('mail', 'annual', 'list'): 1, ('retailers', ...  \n",
       "5   {('trees', 'association', 'rules'): 1, ('self'...  \n",
       "6   {('sometimes', 'insurance', 'reasons'): 1, ('a...  \n",
       "7   {('feasibility', 'stage', 'also'): 1, ('data',...  \n",
       "8   {('processing', 'involved', 'data'): 1, ('bill...  \n",
       "9   {('auditors', 'sec', 'sought'): 1, ('ceo', 'ad...  \n",
       "10  {('developers', 'regards', 'player'): 1, ('reg...  \n",
       "11  {('occurs', 'user', 'able'): 1, ('information'...  \n",
       "12  {('site', 'running', 'slow'): 1, ('discovery',...  \n",
       "13  {('senate', 'bill', 'caused'): 1, ('systems', ...  \n",
       "14  {('learning', 'statistical', 'anomaly'): 1, ('...  \n",
       "15  {('analysis', 'set', 'techniques'): 1, ('may',...  \n",
       "16  {('platform', 'anp', 'agenda'): 1, ('nearly', ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unigrams'] = df['filtered_text'].map(lambda x: make_ngram(x, n=1))\n",
    "df['bigrams'] = df['filtered_text'].map(lambda x: make_ngram(x, n=2))\n",
    "df['trigrams'] = df['filtered_text'].map(lambda x: make_ngram(x, n=3))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def merge_frequency_dictionaries(first: Dict[Tuple[str, ...], int], second: Dict[Tuple[str, ...], int]) -> Dict[Tuple[str, ...], int]:\n",
    "    \"\"\"Merges two dictionaries of frequencies\n",
    "\n",
    "    :param first: first dictionary containing frequencies\n",
    "    :param second: second dictionary containing frequencies\n",
    "    :return: a merged dictionary\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, value in first.items():\n",
    "        res[key] = value\n",
    "    for key, value in second.items():\n",
    "        if key in res:\n",
    "            res[key] += value\n",
    "        else:\n",
    "            res[key] = value\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def combine(series):\n",
    "    \"\"\" Combines a list of dictionaries into a single dictionary\n",
    "\n",
    "    :param series: a list of dictionaries\n",
    "    :return: a single dictionary\n",
    "    \"\"\"\n",
    "    return reduce(lambda x,y: merge_frequency_dictionaries(x,y), series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_most_frequent(grams: pd.Series, n: int) -> list[Tuple[int, Tuple[str, ...]]]:\n",
    "    \"\"\" Returns the n most frequent n-grams\n",
    "\n",
    "    :param grams: a list of dictionaries\n",
    "    :param n: the number of n-grams to return\n",
    "    :return: a list of tuples containing the frequency and the n-gram\n",
    "    \"\"\"\n",
    "    combined_grams = grams.aggregate(combine)\n",
    "    return sorted([(v, k) for k, v in combined_grams.items()], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>10 Most Frequent Unigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(160, ('behavior',)),\n",
       " (156, ('analysis',)),\n",
       " (150, ('data',)),\n",
       " (148, ('business',)),\n",
       " (103, ('also',)),\n",
       " (102, ('text',)),\n",
       " (86, ('anpr',)),\n",
       " (85, ('use',)),\n",
       " (84, ('used',)),\n",
       " (84, ('plate',))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['unigrams'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>10 Most Frequent Bigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(43, ('text', 'mining')),\n",
       " (43, ('license', 'plate')),\n",
       " (33, ('business', 'analysis')),\n",
       " (22, ('data', 'mining')),\n",
       " (20, ('open', 'access')),\n",
       " (19, ('document', 'processing')),\n",
       " (17, ('business', 'analysts')),\n",
       " (17, ('anpr', 'systems')),\n",
       " (16, ('radical', 'behaviorism')),\n",
       " (16, ('behavior', 'analysis'))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['bigrams'], 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>10 Most Frequent Trigrams</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, ('number', 'plate', 'recognition')),\n",
       " (7, ('b', 'f', 'skinner')),\n",
       " (7, ('automatic', 'number', 'plate')),\n",
       " (6, ('optical', 'character', 'recognition')),\n",
       " (6, ('license', 'plate', 'capture')),\n",
       " (6, ('average', 'speed', 'cameras')),\n",
       " (5, ('text', 'data', 'mining')),\n",
       " (5, ('open', 'access', 'content')),\n",
       " (5, ('natural', 'language', 'processing')),\n",
       " (4, ('text', 'mining', 'software'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['trigrams'], 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Making 2 Matrixes:</h4>\n",
    "X = 1700 most frequent n-grams\n",
    "Y = Document Number\n",
    "\n",
    "<ol>\n",
    "<li>  Raw Ngram </li>\n",
    "<li> TF-IDF </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "c) Using SVD, decompose and truncate your numerical features $X = U \\Sigma V^\\top$ into ($docs \\times topics$) and ($topics \\times terms$) matrices (left/right singular vectors, respectively) using $6$ topics. List $5$ most significant $n$-grams for each topic, measured by values of the ($topics \\times terms$) matrix. Do this for both features $X_\\mathrm{raw}$ and $X_\\mathrm{tf-idf}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedSVD_count=TruncatedSVD(6)\n",
    "truncatedSVD_tfidf=TruncatedSVD(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_truncated_count = truncatedSVD.fit_transform(count_matrix)\n",
    "X_truncated_tfidf = truncatedSVD.fit_transform(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "d) Compare and comment the results with respect to the selection of features and the $n$ value in $n$-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**The format of tf-idf you need to use:**\n",
    "\n",
    "$$ f(tf, idf) = (1 + \\ln (tf)) \\cdot idf $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ tf = \\frac{number\\ of\\ times\\ term\\ w\\ appears\\ in\\ a\\ document}{total\\ number\\ of\\ terms\\ in\\ that\\ document} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ idf = \\ln(\\frac{total\\ number\\ of\\ documents}{number\\ of\\ documents\\ with\\ term\\ w\\ in\\ them + 1} + 1) $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "46e771d7cf59df27081d1b1a7d008817c75355cfee57678e9b400438e0926c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
