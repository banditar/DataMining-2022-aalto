{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "\n",
    "| Student Name         | Student-ID |\n",
    "|----------------------|------------|\n",
    "| Marco Di Francesco   | 100632815  |\n",
    "| Loreto García Tejada | 100643862  |\n",
    "| György Bence Józsa   | 100633270  |\n",
    "| József-Hunor Jánosi  | 100516724  |\n",
    "| Sara-Jane Bittner    | 100498554  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Learning goal: Processing text data, converting it into a numerical format and performing topic analysis using SVD._\n",
    "\n",
    "To complete the assignment you are allowed to use the NLTK natural language toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from typing import Union, Tuple, Dict, List\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gyuri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "a) Load _applications_of_DM.csv_, e.g. with `pandas` in Python. It has titles and text content of Wikipedia articles on data mining. In the following tasks, you are to work with the \"tex\"-attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                title  \\\n0                Anomaly Detection at Multiple Scales   \n1                                Behavioral analytics   \n2                                  Business analytics   \n3                             CORE (research service)   \n4                                  Daisy Intelligence   \n5                                        Data Applied   \n6                          Data mining in agriculture   \n7                                       Data thinking   \n8                                 Document processing   \n9                         Equifax Workforce Solutions   \n10                                     Game analytics   \n11                                   Inference attack   \n12                          Path analysis (computing)   \n13  Automatic number-plate recognition in the Unit...   \n14                         PRODIGAL (computer system)   \n15                                        Text mining   \n16                                            Zapaday   \n\n                                                 text  \n0   Anomaly Detection at Multiple Scales, or ADAMS...  \n1   Behaviorism is a systematic approach to unders...  \n2   Business analysis is a professional discipline...  \n3   CORE (Connecting Repositories) is a service pr...  \n4   Daisy Intelligence is a Canadian Artificial In...  \n5   Data Applied is a software vendor headquartere...  \n6   Data mining in agriculture is a recent researc...  \n7   Data thinking is a buzzword for the generic \"m...  \n8   Document processing is a field of research and...  \n9   Equifax Workforce Solutions, formerly known as...  \n10  Game analytics is the form of behavioral analy...  \n11  An Inference Attack is a data mining technique...  \n12  Path analysis, is the analysis of a path, whic...  \n13  Automatic number-plate recognition (ANPR; see ...  \n14  PRODIGAL (proactive discovery of insider threa...  \n15  Text mining, also referred to as text data min...  \n16  Zapaday is a global news calendar. The website...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anomaly Detection at Multiple Scales</td>\n      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Behavioral analytics</td>\n      <td>Behaviorism is a systematic approach to unders...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Business analytics</td>\n      <td>Business analysis is a professional discipline...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CORE (research service)</td>\n      <td>CORE (Connecting Repositories) is a service pr...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daisy Intelligence</td>\n      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Applied</td>\n      <td>Data Applied is a software vendor headquartere...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Data mining in agriculture</td>\n      <td>Data mining in agriculture is a recent researc...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Data thinking</td>\n      <td>Data thinking is a buzzword for the generic \"m...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Document processing</td>\n      <td>Document processing is a field of research and...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Equifax Workforce Solutions</td>\n      <td>Equifax Workforce Solutions, formerly known as...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Game analytics</td>\n      <td>Game analytics is the form of behavioral analy...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Inference attack</td>\n      <td>An Inference Attack is a data mining technique...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Path analysis (computing)</td>\n      <td>Path analysis, is the analysis of a path, whic...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Automatic number-plate recognition in the Unit...</td>\n      <td>Automatic number-plate recognition (ANPR; see ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PRODIGAL (computer system)</td>\n      <td>PRODIGAL (proactive discovery of insider threa...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Text mining</td>\n      <td>Text mining, also referred to as text data min...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Zapaday</td>\n      <td>Zapaday is a global news calendar. The website...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('applications_of_DM.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Process and tokenize the text data: lowercase all words, remove digits, punctuation, any special characters and NLTK’s common English stopwords. List $10$ most frequent $n$-grams, $n = 1, 2, 3,$ and their raw counts. Then, convert $1700$ most frequent $n$-grams, across all $n$-values, into numerical matrices, i.e., features $X_\\mathrm{raw},X_\\mathrm{tf-idf} \\in \\mathbb{R}^{docs \\times terms}$. Features $X_\\mathrm{raw}$ are raw $n$-gram counts, $X_\\mathrm{tf-idf}$ are tf-idf values (see the specific format below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text: str) -> list[str]:\n",
    "    \"\"\"Removes special characters and numbers from a given text and returns a list of words of that text in lower case, removing common english stopwords.\n",
    "\n",
    "    :param text: the raw text to be processed\n",
    "    :return: a list of words in the original text with no special characters, numbers and common english stopwords in lower case.\n",
    "    \"\"\"\n",
    "    # remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())\n",
    "    words = text.split()\n",
    "    # filter out common english stopwords and return list\n",
    "    return [word for word in words if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                title  \\\n0                Anomaly Detection at Multiple Scales   \n1                                Behavioral analytics   \n2                                  Business analytics   \n3                             CORE (research service)   \n4                                  Daisy Intelligence   \n5                                        Data Applied   \n6                          Data mining in agriculture   \n7                                       Data thinking   \n8                                 Document processing   \n9                         Equifax Workforce Solutions   \n10                                     Game analytics   \n11                                   Inference attack   \n12                          Path analysis (computing)   \n13  Automatic number-plate recognition in the Unit...   \n14                         PRODIGAL (computer system)   \n15                                        Text mining   \n16                                            Zapaday   \n\n                                                 text  \\\n0   Anomaly Detection at Multiple Scales, or ADAMS...   \n1   Behaviorism is a systematic approach to unders...   \n2   Business analysis is a professional discipline...   \n3   CORE (Connecting Repositories) is a service pr...   \n4   Daisy Intelligence is a Canadian Artificial In...   \n5   Data Applied is a software vendor headquartere...   \n6   Data mining in agriculture is a recent researc...   \n7   Data thinking is a buzzword for the generic \"m...   \n8   Document processing is a field of research and...   \n9   Equifax Workforce Solutions, formerly known as...   \n10  Game analytics is the form of behavioral analy...   \n11  An Inference Attack is a data mining technique...   \n12  Path analysis, is the analysis of a path, whic...   \n13  Automatic number-plate recognition (ANPR; see ...   \n14  PRODIGAL (proactive discovery of insider threa...   \n15  Text mining, also referred to as text data min...   \n16  Zapaday is a global news calendar. The website...   \n\n                                        filtered_text  \n0   [anomaly, detection, multiple, scales, adams, ...  \n1   [behaviorism, systematic, approach, understand...  \n2   [business, analysis, professional, discipline,...  \n3   [core, connecting, repositories, service, prov...  \n4   [daisy, intelligence, canadian, artificial, in...  \n5   [data, applied, software, vendor, headquartere...  \n6   [data, mining, agriculture, recent, research, ...  \n7   [data, thinking, buzzword, generic, mental, pa...  \n8   [document, processing, field, research, set, p...  \n9   [equifax, workforce, solutions, formerly, know...  \n10  [game, analytics, form, behavioral, analytics,...  \n11  [inference, attack, data, mining, technique, p...  \n12  [path, analysis, analysis, path, portrayal, ch...  \n13  [automatic, number, plate, recognition, anpr, ...  \n14  [prodigal, proactive, discovery, insider, thre...  \n15  [text, mining, also, referred, text, data, min...  \n16  [zapaday, global, news, calendar, website, pub...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>filtered_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anomaly Detection at Multiple Scales</td>\n      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n      <td>[anomaly, detection, multiple, scales, adams, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Behavioral analytics</td>\n      <td>Behaviorism is a systematic approach to unders...</td>\n      <td>[behaviorism, systematic, approach, understand...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Business analytics</td>\n      <td>Business analysis is a professional discipline...</td>\n      <td>[business, analysis, professional, discipline,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CORE (research service)</td>\n      <td>CORE (Connecting Repositories) is a service pr...</td>\n      <td>[core, connecting, repositories, service, prov...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daisy Intelligence</td>\n      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n      <td>[daisy, intelligence, canadian, artificial, in...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Applied</td>\n      <td>Data Applied is a software vendor headquartere...</td>\n      <td>[data, applied, software, vendor, headquartere...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Data mining in agriculture</td>\n      <td>Data mining in agriculture is a recent researc...</td>\n      <td>[data, mining, agriculture, recent, research, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Data thinking</td>\n      <td>Data thinking is a buzzword for the generic \"m...</td>\n      <td>[data, thinking, buzzword, generic, mental, pa...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Document processing</td>\n      <td>Document processing is a field of research and...</td>\n      <td>[document, processing, field, research, set, p...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Equifax Workforce Solutions</td>\n      <td>Equifax Workforce Solutions, formerly known as...</td>\n      <td>[equifax, workforce, solutions, formerly, know...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Game analytics</td>\n      <td>Game analytics is the form of behavioral analy...</td>\n      <td>[game, analytics, form, behavioral, analytics,...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Inference attack</td>\n      <td>An Inference Attack is a data mining technique...</td>\n      <td>[inference, attack, data, mining, technique, p...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Path analysis (computing)</td>\n      <td>Path analysis, is the analysis of a path, whic...</td>\n      <td>[path, analysis, analysis, path, portrayal, ch...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Automatic number-plate recognition in the Unit...</td>\n      <td>Automatic number-plate recognition (ANPR; see ...</td>\n      <td>[automatic, number, plate, recognition, anpr, ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PRODIGAL (computer system)</td>\n      <td>PRODIGAL (proactive discovery of insider threa...</td>\n      <td>[prodigal, proactive, discovery, insider, thre...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Text mining</td>\n      <td>Text mining, also referred to as text data min...</td>\n      <td>[text, mining, also, referred, text, data, min...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Zapaday</td>\n      <td>Zapaday is a global news calendar. The website...</td>\n      <td>[zapaday, global, news, calendar, website, pub...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_text'] = df['text'].map(process_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngram(corpus: list[str], n: int) -> Dict[Tuple[str, ...], int]:\n",
    "    \"\"\"Creates a frequency-list of specified n-grams in the given corpus\n",
    "\n",
    "    :param corpus: Ordered list of words in the corpus\n",
    "    :param n: number of elements in n-gram creation\n",
    "    :return: dictionary with keys being unique n-grams and values being the frequencies of them\n",
    "    \"\"\"\n",
    "    grams = list(ngrams(corpus, n))\n",
    "    return {i: grams.count(i) for i in set(grams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 100 100 289\n",
      "1515 3273 3576 8364\n",
      "936 1843 2000 4779\n",
      "308 529 578 1415\n",
      "59 66 65 190\n",
      "47 54 55 156\n",
      "412 617 656 1685\n",
      "204 312 336 852\n",
      "303 484 518 1305\n",
      "373 576 611 1560\n",
      "59 70 72 201\n",
      "95 124 127 346\n",
      "290 505 544 1339\n",
      "1892 4231 4571 10694\n",
      "131 155 156 442\n",
      "878 1605 1731 4214\n",
      "141 210 222 573\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                title  \\\n0                Anomaly Detection at Multiple Scales   \n1                                Behavioral analytics   \n2                                  Business analytics   \n3                             CORE (research service)   \n4                                  Daisy Intelligence   \n5                                        Data Applied   \n6                          Data mining in agriculture   \n7                                       Data thinking   \n8                                 Document processing   \n9                         Equifax Workforce Solutions   \n10                                     Game analytics   \n11                                   Inference attack   \n12                          Path analysis (computing)   \n13  Automatic number-plate recognition in the Unit...   \n14                         PRODIGAL (computer system)   \n15                                        Text mining   \n16                                            Zapaday   \n\n                                                 text  \\\n0   Anomaly Detection at Multiple Scales, or ADAMS...   \n1   Behaviorism is a systematic approach to unders...   \n2   Business analysis is a professional discipline...   \n3   CORE (Connecting Repositories) is a service pr...   \n4   Daisy Intelligence is a Canadian Artificial In...   \n5   Data Applied is a software vendor headquartere...   \n6   Data mining in agriculture is a recent researc...   \n7   Data thinking is a buzzword for the generic \"m...   \n8   Document processing is a field of research and...   \n9   Equifax Workforce Solutions, formerly known as...   \n10  Game analytics is the form of behavioral analy...   \n11  An Inference Attack is a data mining technique...   \n12  Path analysis, is the analysis of a path, whic...   \n13  Automatic number-plate recognition (ANPR; see ...   \n14  PRODIGAL (proactive discovery of insider threa...   \n15  Text mining, also referred to as text data min...   \n16  Zapaday is a global news calendar. The website...   \n\n                                        filtered_text  \\\n0   [anomaly, detection, multiple, scales, adams, ...   \n1   [behaviorism, systematic, approach, understand...   \n2   [business, analysis, professional, discipline,...   \n3   [core, connecting, repositories, service, prov...   \n4   [daisy, intelligence, canadian, artificial, in...   \n5   [data, applied, software, vendor, headquartere...   \n6   [data, mining, agriculture, recent, research, ...   \n7   [data, thinking, buzzword, generic, mental, pa...   \n8   [document, processing, field, research, set, p...   \n9   [equifax, workforce, solutions, formerly, know...   \n10  [game, analytics, form, behavioral, analytics,...   \n11  [inference, attack, data, mining, technique, p...   \n12  [path, analysis, analysis, path, portrayal, ch...   \n13  [automatic, number, plate, recognition, anpr, ...   \n14  [prodigal, proactive, discovery, insider, thre...   \n15  [text, mining, also, referred, text, data, min...   \n16  [zapaday, global, news, calendar, website, pub...   \n\n                                             unigrams  \\\n0   {('adams',): 2, ('office',): 1, ('detection',)...   \n1   {('otherwise',): 1, ('versions',): 1, ('others...   \n2   {('change',): 11, ('otherwise',): 1, ('effecti...   \n3   {('analytics',): 1, ('used',): 1, ('including'...   \n4   {('ai',): 3, ('suburban',): 1, ('promotional',...   \n5   {('vendor',): 1, ('rules',): 1, ('analytical',...   \n6   {('primary',): 1, ('correct',): 1, ('done',): ...   \n7   {('assessments',): 1, ('digital',): 1, ('model...   \n8   {('line',): 1, ('digital',): 4, ('emerged',): ...   \n9   {('knew',): 1, ('items',): 1, ('correct',): 1,...   \n10  {('back',): 1, ('number',): 2, ('quantitative'...   \n11  {('highly',): 1, ('accessed',): 1, ('meter',):...   \n12  {('items',): 1, ('page',): 9, ('following',): ...   \n13  {('versions',): 2, ('others',): 2, ('quick',):...   \n14  {('actions',): 1, ('serious',): 1, ('amherst',...   \n15  {('otherwise',): 1, ('others',): 2, ('items',)...   \n16  {('others',): 1, ('white',): 1, ('topic',): 1,...   \n\n                                              bigrams  \\\n0   {('good', 'mental'): 1, ('project', 'georgia')...   \n1   {('rating', 'modern'): 1, ('children', 'used')...   \n2   {('resources', 'costs'): 1, ('need', 'well'): ...   \n3   {('must', 'openly'): 1, ('point', 'develop'): ...   \n4   {('claims', 'company'): 1, ('ai', 'technology'...   \n5   {('mining', 'product'): 1, ('maps', 'time'): 1...   \n6   {('agriculture', 'data'): 1, ('exclusively', '...   \n7   {('typically', 'applied'): 1, ('proof', 'conce...   \n8   {('massively', 'extracting'): 1, ('automatical...   \n9   {('percent', 'inflated'): 1, ('financial', 'ta...   \n10  {('high', 'number'): 1, ('analytics', 'platfor...   \n11  {('voice', 'commands'): 1, ('without', 'user')...   \n12  {('one', 'company'): 1, ('websites', 'path'): ...   \n13  {('canada', 'federal'): 1, ('unlawful', 'regul...   \n14  {('counterintelligence', 'georgia'): 1, ('sour...   \n15  {('personal', 'text'): 1, ('stems', 'refocusin...   \n16  {('journalists', 'syndicate'): 1, ('creator', ...   \n\n                                             trigrams  \\\n0   {('researcher', 'david', 'bader'): 1, ('innoce...   \n1   {('groups', 'sigs', 'within'): 1, ('analysis',...   \n2   {('matrix', 'example', 'table'): 1, ('generall...   \n3   {('mine', 'large', 'amounts'): 1, ('project', ...   \n4   {('globe', 'mail', 'annual'): 1, ('ai', 'techn...   \n5   {('reporting', 'tree', 'maps'): 1, ('outlier',...   \n6   {('techniques', 'k', 'means'): 1, ('allow', 'f...   \n7   {('applied', 'step', 'developed'): 1, ('availa...   \n8   {('documents', 'newspaper', 'archives'): 1, ('...   \n9   {('competition', 'talx', 'believed'): 1, ('sho...   \n10  {('using', 'quantitative', 'measures'): 1, ('g...   \n11  {('data', 'order', 'illegitimately'): 1, ('ill...   \n12  {('visual', 'representation', 'real'): 1, ('us...   \n13  {('driver', 'systems', 'commonly'): 1, ('custo...   \n14  {('nidal', 'malik', 'hasan'): 1, ('agency', 'a...   \n15  {('used', 'support', 'competitive'): 1, ('cont...   \n16  {('monitor', 'news', 'sites'): 1, ('profession...   \n\n                                            all_grams  \n0   {('adams',): 2, ('office',): 1, ('detection',)...  \n1   {('otherwise',): 1, ('versions',): 1, ('others...  \n2   {('change',): 11, ('otherwise',): 1, ('effecti...  \n3   {('analytics',): 1, ('used',): 1, ('including'...  \n4   {('ai',): 3, ('suburban',): 1, ('promotional',...  \n5   {('vendor',): 1, ('rules',): 1, ('analytical',...  \n6   {('primary',): 1, ('correct',): 1, ('done',): ...  \n7   {('assessments',): 1, ('digital',): 1, ('model...  \n8   {('line',): 1, ('digital',): 4, ('emerged',): ...  \n9   {('knew',): 1, ('items',): 1, ('correct',): 1,...  \n10  {('back',): 1, ('number',): 2, ('quantitative'...  \n11  {('highly',): 1, ('accessed',): 1, ('meter',):...  \n12  {('items',): 1, ('page',): 9, ('following',): ...  \n13  {('versions',): 2, ('others',): 2, ('quick',):...  \n14  {('actions',): 1, ('serious',): 1, ('amherst',...  \n15  {('otherwise',): 1, ('others',): 2, ('items',)...  \n16  {('others',): 1, ('white',): 1, ('topic',): 1,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>filtered_text</th>\n      <th>unigrams</th>\n      <th>bigrams</th>\n      <th>trigrams</th>\n      <th>all_grams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anomaly Detection at Multiple Scales</td>\n      <td>Anomaly Detection at Multiple Scales, or ADAMS...</td>\n      <td>[anomaly, detection, multiple, scales, adams, ...</td>\n      <td>{('adams',): 2, ('office',): 1, ('detection',)...</td>\n      <td>{('good', 'mental'): 1, ('project', 'georgia')...</td>\n      <td>{('researcher', 'david', 'bader'): 1, ('innoce...</td>\n      <td>{('adams',): 2, ('office',): 1, ('detection',)...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Behavioral analytics</td>\n      <td>Behaviorism is a systematic approach to unders...</td>\n      <td>[behaviorism, systematic, approach, understand...</td>\n      <td>{('otherwise',): 1, ('versions',): 1, ('others...</td>\n      <td>{('rating', 'modern'): 1, ('children', 'used')...</td>\n      <td>{('groups', 'sigs', 'within'): 1, ('analysis',...</td>\n      <td>{('otherwise',): 1, ('versions',): 1, ('others...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Business analytics</td>\n      <td>Business analysis is a professional discipline...</td>\n      <td>[business, analysis, professional, discipline,...</td>\n      <td>{('change',): 11, ('otherwise',): 1, ('effecti...</td>\n      <td>{('resources', 'costs'): 1, ('need', 'well'): ...</td>\n      <td>{('matrix', 'example', 'table'): 1, ('generall...</td>\n      <td>{('change',): 11, ('otherwise',): 1, ('effecti...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CORE (research service)</td>\n      <td>CORE (Connecting Repositories) is a service pr...</td>\n      <td>[core, connecting, repositories, service, prov...</td>\n      <td>{('analytics',): 1, ('used',): 1, ('including'...</td>\n      <td>{('must', 'openly'): 1, ('point', 'develop'): ...</td>\n      <td>{('mine', 'large', 'amounts'): 1, ('project', ...</td>\n      <td>{('analytics',): 1, ('used',): 1, ('including'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daisy Intelligence</td>\n      <td>Daisy Intelligence is a Canadian Artificial In...</td>\n      <td>[daisy, intelligence, canadian, artificial, in...</td>\n      <td>{('ai',): 3, ('suburban',): 1, ('promotional',...</td>\n      <td>{('claims', 'company'): 1, ('ai', 'technology'...</td>\n      <td>{('globe', 'mail', 'annual'): 1, ('ai', 'techn...</td>\n      <td>{('ai',): 3, ('suburban',): 1, ('promotional',...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Applied</td>\n      <td>Data Applied is a software vendor headquartere...</td>\n      <td>[data, applied, software, vendor, headquartere...</td>\n      <td>{('vendor',): 1, ('rules',): 1, ('analytical',...</td>\n      <td>{('mining', 'product'): 1, ('maps', 'time'): 1...</td>\n      <td>{('reporting', 'tree', 'maps'): 1, ('outlier',...</td>\n      <td>{('vendor',): 1, ('rules',): 1, ('analytical',...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Data mining in agriculture</td>\n      <td>Data mining in agriculture is a recent researc...</td>\n      <td>[data, mining, agriculture, recent, research, ...</td>\n      <td>{('primary',): 1, ('correct',): 1, ('done',): ...</td>\n      <td>{('agriculture', 'data'): 1, ('exclusively', '...</td>\n      <td>{('techniques', 'k', 'means'): 1, ('allow', 'f...</td>\n      <td>{('primary',): 1, ('correct',): 1, ('done',): ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Data thinking</td>\n      <td>Data thinking is a buzzword for the generic \"m...</td>\n      <td>[data, thinking, buzzword, generic, mental, pa...</td>\n      <td>{('assessments',): 1, ('digital',): 1, ('model...</td>\n      <td>{('typically', 'applied'): 1, ('proof', 'conce...</td>\n      <td>{('applied', 'step', 'developed'): 1, ('availa...</td>\n      <td>{('assessments',): 1, ('digital',): 1, ('model...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Document processing</td>\n      <td>Document processing is a field of research and...</td>\n      <td>[document, processing, field, research, set, p...</td>\n      <td>{('line',): 1, ('digital',): 4, ('emerged',): ...</td>\n      <td>{('massively', 'extracting'): 1, ('automatical...</td>\n      <td>{('documents', 'newspaper', 'archives'): 1, ('...</td>\n      <td>{('line',): 1, ('digital',): 4, ('emerged',): ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Equifax Workforce Solutions</td>\n      <td>Equifax Workforce Solutions, formerly known as...</td>\n      <td>[equifax, workforce, solutions, formerly, know...</td>\n      <td>{('knew',): 1, ('items',): 1, ('correct',): 1,...</td>\n      <td>{('percent', 'inflated'): 1, ('financial', 'ta...</td>\n      <td>{('competition', 'talx', 'believed'): 1, ('sho...</td>\n      <td>{('knew',): 1, ('items',): 1, ('correct',): 1,...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Game analytics</td>\n      <td>Game analytics is the form of behavioral analy...</td>\n      <td>[game, analytics, form, behavioral, analytics,...</td>\n      <td>{('back',): 1, ('number',): 2, ('quantitative'...</td>\n      <td>{('high', 'number'): 1, ('analytics', 'platfor...</td>\n      <td>{('using', 'quantitative', 'measures'): 1, ('g...</td>\n      <td>{('back',): 1, ('number',): 2, ('quantitative'...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Inference attack</td>\n      <td>An Inference Attack is a data mining technique...</td>\n      <td>[inference, attack, data, mining, technique, p...</td>\n      <td>{('highly',): 1, ('accessed',): 1, ('meter',):...</td>\n      <td>{('voice', 'commands'): 1, ('without', 'user')...</td>\n      <td>{('data', 'order', 'illegitimately'): 1, ('ill...</td>\n      <td>{('highly',): 1, ('accessed',): 1, ('meter',):...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Path analysis (computing)</td>\n      <td>Path analysis, is the analysis of a path, whic...</td>\n      <td>[path, analysis, analysis, path, portrayal, ch...</td>\n      <td>{('items',): 1, ('page',): 9, ('following',): ...</td>\n      <td>{('one', 'company'): 1, ('websites', 'path'): ...</td>\n      <td>{('visual', 'representation', 'real'): 1, ('us...</td>\n      <td>{('items',): 1, ('page',): 9, ('following',): ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Automatic number-plate recognition in the Unit...</td>\n      <td>Automatic number-plate recognition (ANPR; see ...</td>\n      <td>[automatic, number, plate, recognition, anpr, ...</td>\n      <td>{('versions',): 2, ('others',): 2, ('quick',):...</td>\n      <td>{('canada', 'federal'): 1, ('unlawful', 'regul...</td>\n      <td>{('driver', 'systems', 'commonly'): 1, ('custo...</td>\n      <td>{('versions',): 2, ('others',): 2, ('quick',):...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>PRODIGAL (computer system)</td>\n      <td>PRODIGAL (proactive discovery of insider threa...</td>\n      <td>[prodigal, proactive, discovery, insider, thre...</td>\n      <td>{('actions',): 1, ('serious',): 1, ('amherst',...</td>\n      <td>{('counterintelligence', 'georgia'): 1, ('sour...</td>\n      <td>{('nidal', 'malik', 'hasan'): 1, ('agency', 'a...</td>\n      <td>{('actions',): 1, ('serious',): 1, ('amherst',...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Text mining</td>\n      <td>Text mining, also referred to as text data min...</td>\n      <td>[text, mining, also, referred, text, data, min...</td>\n      <td>{('otherwise',): 1, ('others',): 2, ('items',)...</td>\n      <td>{('personal', 'text'): 1, ('stems', 'refocusin...</td>\n      <td>{('used', 'support', 'competitive'): 1, ('cont...</td>\n      <td>{('otherwise',): 1, ('others',): 2, ('items',)...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Zapaday</td>\n      <td>Zapaday is a global news calendar. The website...</td>\n      <td>[zapaday, global, news, calendar, website, pub...</td>\n      <td>{('others',): 1, ('white',): 1, ('topic',): 1,...</td>\n      <td>{('journalists', 'syndicate'): 1, ('creator', ...</td>\n      <td>{('monitor', 'news', 'sites'): 1, ('profession...</td>\n      <td>{('others',): 1, ('white',): 1, ('topic',): 1,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unigrams'] = df['filtered_text'].map(lambda x: make_ngram(x, n=1))\n",
    "df['bigrams'] = df['filtered_text'].map(lambda x: make_ngram(x, n=2))\n",
    "df['trigrams'] = df['filtered_text'].map(lambda x: make_ngram(x, n=3))\n",
    "df[\"all_grams\"] = \"{}\"\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    row[\"all_grams\"] = {**row['unigrams'], **row[\"bigrams\"], **row[\"trigrams\"]}\n",
    "\n",
    "for _, g in df.iterrows():\n",
    "    print(len(g[\"unigrams\"]), len(g[\"bigrams\"]), len(g[\"trigrams\"]), len(g[\"all_grams\"]))\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def merge_frequency_dictionaries(first: Dict[Tuple[str, ...], int], second: Dict[Tuple[str, ...], int]) -> Dict[\n",
    "    Tuple[str, ...], int]:\n",
    "    \"\"\"Merges two dictionaries of frequencies\n",
    "\n",
    "    :param first: first dictionary containing frequencies\n",
    "    :param second: second dictionary containing frequencies\n",
    "    :return: a merged dictionary\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, value in first.items():\n",
    "        res[key] = value\n",
    "    for key, value in second.items():\n",
    "        if key in res:\n",
    "            res[key] += value\n",
    "        else:\n",
    "            res[key] = value\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def combine(series):\n",
    "    \"\"\" Combines a list of dictionaries into a single dictionary\n",
    "\n",
    "    :param series: a list of dictionaries\n",
    "    :return: a single dictionary\n",
    "    \"\"\"\n",
    "    return reduce(lambda x, y: merge_frequency_dictionaries(x, y), series)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_most_frequent(grams: pd.Series, n: int) -> list[Tuple[int, Tuple[str, ...]]]:\n",
    "    \"\"\" Returns the n most frequent n-grams\n",
    "\n",
    "    :param grams: a list of dictionaries\n",
    "    :param n: the number of n-grams to return\n",
    "    :return: a list of tuples containing the frequency and the n-gram\n",
    "    \"\"\"\n",
    "    combined_grams = grams.aggregate(combine)\n",
    "    return sorted([(v, k) for k, v in combined_grams.items()], reverse=True)[:n]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[(160, ('behavior',)),\n (156, ('analysis',)),\n (150, ('data',)),\n (148, ('business',)),\n (103, ('also',)),\n (102, ('text',)),\n (86, ('anpr',)),\n (85, ('use',)),\n (84, ('used',)),\n (84, ('plate',))]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['unigrams'], 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[(43, ('text', 'mining')),\n (43, ('license', 'plate')),\n (33, ('business', 'analysis')),\n (22, ('data', 'mining')),\n (20, ('open', 'access')),\n (19, ('document', 'processing')),\n (17, ('business', 'analysts')),\n (17, ('anpr', 'systems')),\n (16, ('radical', 'behaviorism')),\n (16, ('behavior', 'analysis'))]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['bigrams'], 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[(8, ('number', 'plate', 'recognition')),\n (7, ('b', 'f', 'skinner')),\n (7, ('automatic', 'number', 'plate')),\n (6, ('optical', 'character', 'recognition')),\n (6, ('license', 'plate', 'capture')),\n (6, ('average', 'speed', 'cameras')),\n (5, ('text', 'data', 'mining')),\n (5, ('open', 'access', 'content')),\n (5, ('natural', 'language', 'processing')),\n (4, ('text', 'mining', 'software'))]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['trigrams'], 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[(160, ('behavior',)),\n (156, ('analysis',)),\n (150, ('data',)),\n (148, ('business',)),\n (103, ('also',)),\n (102, ('text',)),\n (86, ('anpr',)),\n (85, ('use',)),\n (84, ('used',)),\n (84, ('plate',))]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(df['all_grams'], 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    (behavior,)  (analysis,)  \\\ntitle                                                                          \nAnomaly Detection at Multiple Scales                        0.0          1.0   \nBehavioral analytics                                      154.0         30.0   \nBusiness analytics                                          0.0         55.0   \nCORE (research service)                                     0.0          1.0   \nDaisy Intelligence                                          0.0          1.0   \nData Applied                                                0.0          2.0   \nData mining in agriculture                                  0.0          2.0   \nData thinking                                               0.0          4.0   \nDocument processing                                         0.0          1.0   \nEquifax Workforce Solutions                                 0.0          0.0   \nGame analytics                                              0.0          1.0   \nInference attack                                            1.0          0.0   \nPath analysis (computing)                                   2.0         24.0   \nAutomatic number-plate recognition in the Unite...          1.0          1.0   \nPRODIGAL (computer system)                                  2.0          3.0   \nText mining                                                 0.0         30.0   \nZapaday                                                     0.0          0.0   \n\n                                                    (data,)  (business,)  \\\ntitle                                                                      \nAnomaly Detection at Multiple Scales                    1.0          0.0   \nBehavioral analytics                                    2.0          1.0   \nBusiness analytics                                      6.0        122.0   \nCORE (research service)                                 9.0          0.0   \nDaisy Intelligence                                      1.0          0.0   \nData Applied                                            6.0          1.0   \nData mining in agriculture                             19.0          0.0   \nData thinking                                          31.0          5.0   \nDocument processing                                     9.0          2.0   \nEquifax Workforce Solutions                             0.0          4.0   \nGame analytics                                          2.0          1.0   \nInference attack                                        6.0          0.0   \nPath analysis (computing)                               6.0          2.0   \nAutomatic number-plate recognition in the Unite...     25.0          0.0   \nPRODIGAL (computer system)                              4.0          0.0   \nText mining                                            23.0         10.0   \nZapaday                                                 0.0          0.0   \n\n                                                    (also,)  (text,)  (anpr,)  \\\ntitle                                                                           \nAnomaly Detection at Multiple Scales                    0.0      0.0      0.0   \nBehavioral analytics                                   26.0      0.0      0.0   \nBusiness analytics                                      8.0      0.0      0.0   \nCORE (research service)                                 3.0      7.0      0.0   \nDaisy Intelligence                                      1.0      0.0      0.0   \nData Applied                                            0.0      0.0      0.0   \nData mining in agriculture                              5.0      0.0      0.0   \nData thinking                                           4.0      0.0      0.0   \nDocument processing                                    11.0      6.0      0.0   \nEquifax Workforce Solutions                             6.0      0.0      0.0   \nGame analytics                                          0.0      0.0      0.0   \nInference attack                                        2.0      0.0      0.0   \nPath analysis (computing)                               3.0      1.0      0.0   \nAutomatic number-plate recognition in the Unite...     24.0      1.0     86.0   \nPRODIGAL (computer system)                              0.0      1.0      0.0   \nText mining                                             9.0     86.0      0.0   \nZapaday                                                 1.0      0.0      0.0   \n\n                                                    (use,)  (used,)  (plate,)  \\\ntitle                                                                           \nAnomaly Detection at Multiple Scales                   0.0      0.0       0.0   \nBehavioral analytics                                  10.0     10.0       0.0   \nBusiness analytics                                     3.0     13.0       0.0   \nCORE (research service)                                4.0      1.0       0.0   \nDaisy Intelligence                                     0.0      0.0       0.0   \nData Applied                                           0.0      0.0       0.0   \nData mining in agriculture                             6.0      9.0       0.0   \nData thinking                                          3.0      0.0       0.0   \nDocument processing                                    4.0      6.0       0.0   \nEquifax Workforce Solutions                            0.0      0.0       0.0   \nGame analytics                                         0.0      1.0       0.0   \nInference attack                                       0.0      1.0       0.0   \nPath analysis (computing)                              1.0      0.0       0.0   \nAutomatic number-plate recognition in the Unite...    41.0     32.0      84.0   \nPRODIGAL (computer system)                             0.0      0.0       0.0   \nText mining                                           11.0     11.0       0.0   \nZapaday                                                2.0      0.0       0.0   \n\n                                                    ...  (defense,)  \\\ntitle                                               ...               \nAnomaly Detection at Multiple Scales                ...         0.0   \nBehavioral analytics                                ...         0.0   \nBusiness analytics                                  ...         0.0   \nCORE (research service)                             ...         0.0   \nDaisy Intelligence                                  ...         0.0   \nData Applied                                        ...         0.0   \nData mining in agriculture                          ...         0.0   \nData thinking                                       ...         0.0   \nDocument processing                                 ...         0.0   \nEquifax Workforce Solutions                         ...         0.0   \nGame analytics                                      ...         0.0   \nInference attack                                    ...         0.0   \nPath analysis (computing)                           ...         0.0   \nAutomatic number-plate recognition in the Unite...  ...         1.0   \nPRODIGAL (computer system)                          ...         2.0   \nText mining                                         ...         0.0   \nZapaday                                             ...         0.0   \n\n                                                    (dedicated,)  (decades,)  \\\ntitle                                                                          \nAnomaly Detection at Multiple Scales                         0.0         0.0   \nBehavioral analytics                                         0.0         1.0   \nBusiness analytics                                           0.0         0.0   \nCORE (research service)                                      0.0         0.0   \nDaisy Intelligence                                           0.0         0.0   \nData Applied                                                 0.0         0.0   \nData mining in agriculture                                   0.0         1.0   \nData thinking                                                0.0         0.0   \nDocument processing                                          0.0         0.0   \nEquifax Workforce Solutions                                  0.0         0.0   \nGame analytics                                               0.0         0.0   \nInference attack                                             0.0         0.0   \nPath analysis (computing)                                    0.0         0.0   \nAutomatic number-plate recognition in the Unite...           3.0         0.0   \nPRODIGAL (computer system)                                   0.0         0.0   \nText mining                                                  0.0         1.0   \nZapaday                                                      0.0         0.0   \n\n                                                    (decade,)  (dbt,)  \\\ntitle                                                                   \nAnomaly Detection at Multiple Scales                      0.0     0.0   \nBehavioral analytics                                      1.0     3.0   \nBusiness analytics                                        0.0     0.0   \nCORE (research service)                                   0.0     0.0   \nDaisy Intelligence                                        0.0     0.0   \nData Applied                                              0.0     0.0   \nData mining in agriculture                                0.0     0.0   \nData thinking                                             0.0     0.0   \nDocument processing                                       0.0     0.0   \nEquifax Workforce Solutions                               0.0     0.0   \nGame analytics                                            0.0     0.0   \nInference attack                                          0.0     0.0   \nPath analysis (computing)                                 0.0     0.0   \nAutomatic number-plate recognition in the Unite...        0.0     0.0   \nPRODIGAL (computer system)                                0.0     0.0   \nText mining                                               2.0     0.0   \nZapaday                                                   0.0     0.0   \n\n                                                    (dataset,)  \\\ntitle                                                            \nAnomaly Detection at Multiple Scales                       0.0   \nBehavioral analytics                                       0.0   \nBusiness analytics                                         0.0   \nCORE (research service)                                    1.0   \nDaisy Intelligence                                         0.0   \nData Applied                                               0.0   \nData mining in agriculture                                 0.0   \nData thinking                                              0.0   \nDocument processing                                        0.0   \nEquifax Workforce Solutions                                0.0   \nGame analytics                                             0.0   \nInference attack                                           0.0   \nPath analysis (computing)                                  0.0   \nAutomatic number-plate recognition in the Unite...         2.0   \nPRODIGAL (computer system)                                 0.0   \nText mining                                                0.0   \nZapaday                                                    0.0   \n\n                                                    (data, science)  \\\ntitle                                                                 \nAnomaly Detection at Multiple Scales                            0.0   \nBehavioral analytics                                            0.0   \nBusiness analytics                                              0.0   \nCORE (research service)                                         0.0   \nDaisy Intelligence                                              0.0   \nData Applied                                                    0.0   \nData mining in agriculture                                      0.0   \nData thinking                                                   3.0   \nDocument processing                                             0.0   \nEquifax Workforce Solutions                                     0.0   \nGame analytics                                                  0.0   \nInference attack                                                0.0   \nPath analysis (computing)                                       0.0   \nAutomatic number-plate recognition in the Unite...              0.0   \nPRODIGAL (computer system)                                      0.0   \nText mining                                                     0.0   \nZapaday                                                         0.0   \n\n                                                    (data, mining, techniques)  \\\ntitle                                                                            \nAnomaly Detection at Multiple Scales                                       0.0   \nBehavioral analytics                                                       0.0   \nBusiness analytics                                                         0.0   \nCORE (research service)                                                    0.0   \nDaisy Intelligence                                                         0.0   \nData Applied                                                               0.0   \nData mining in agriculture                                                 2.0   \nData thinking                                                              0.0   \nDocument processing                                                        0.0   \nEquifax Workforce Solutions                                                0.0   \nGame analytics                                                             0.0   \nInference attack                                                           0.0   \nPath analysis (computing)                                                  0.0   \nAutomatic number-plate recognition in the Unite...                         0.0   \nPRODIGAL (computer system)                                                 0.0   \nText mining                                                                1.0   \nZapaday                                                                    0.0   \n\n                                                    (data, entry)  \\\ntitle                                                               \nAnomaly Detection at Multiple Scales                          0.0   \nBehavioral analytics                                          0.0   \nBusiness analytics                                            0.0   \nCORE (research service)                                       0.0   \nDaisy Intelligence                                            0.0   \nData Applied                                                  0.0   \nData mining in agriculture                                    0.0   \nData thinking                                                 0.0   \nDocument processing                                           3.0   \nEquifax Workforce Solutions                                   0.0   \nGame analytics                                                0.0   \nInference attack                                              0.0   \nPath analysis (computing)                                     0.0   \nAutomatic number-plate recognition in the Unite...            0.0   \nPRODIGAL (computer system)                                    0.0   \nText mining                                                   0.0   \nZapaday                                                       0.0   \n\n                                                    (data, centre)  \ntitle                                                               \nAnomaly Detection at Multiple Scales                           0.0  \nBehavioral analytics                                           0.0  \nBusiness analytics                                             0.0  \nCORE (research service)                                        0.0  \nDaisy Intelligence                                             0.0  \nData Applied                                                   0.0  \nData mining in agriculture                                     0.0  \nData thinking                                                  0.0  \nDocument processing                                            0.0  \nEquifax Workforce Solutions                                    0.0  \nGame analytics                                                 0.0  \nInference attack                                               0.0  \nPath analysis (computing)                                      0.0  \nAutomatic number-plate recognition in the Unite...             3.0  \nPRODIGAL (computer system)                                     0.0  \nText mining                                                    0.0  \nZapaday                                                        0.0  \n\n[17 rows x 1700 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>(behavior,)</th>\n      <th>(analysis,)</th>\n      <th>(data,)</th>\n      <th>(business,)</th>\n      <th>(also,)</th>\n      <th>(text,)</th>\n      <th>(anpr,)</th>\n      <th>(use,)</th>\n      <th>(used,)</th>\n      <th>(plate,)</th>\n      <th>...</th>\n      <th>(defense,)</th>\n      <th>(dedicated,)</th>\n      <th>(decades,)</th>\n      <th>(decade,)</th>\n      <th>(dbt,)</th>\n      <th>(dataset,)</th>\n      <th>(data, science)</th>\n      <th>(data, mining, techniques)</th>\n      <th>(data, entry)</th>\n      <th>(data, centre)</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Anomaly Detection at Multiple Scales</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Behavioral analytics</th>\n      <td>154.0</td>\n      <td>30.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>26.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Business analytics</th>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>6.0</td>\n      <td>122.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>CORE (research service)</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Daisy Intelligence</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Data Applied</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Data mining in agriculture</th>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Data thinking</th>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>31.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Document processing</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Equifax Workforce Solutions</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Game analytics</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Inference attack</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Path analysis (computing)</th>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Automatic number-plate recognition in the United Kingdom</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>86.0</td>\n      <td>41.0</td>\n      <td>32.0</td>\n      <td>84.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>PRODIGAL (computer system)</th>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Text mining</th>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>23.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>86.0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Zapaday</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17 rows × 1700 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_count_matrix(ngram: str = \"all_grams\") -> pd.DataFrame:\n",
    "    \"\"\"Returns a raw count matrix for the given n-gram.\n",
    "\n",
    "    The matrix should contain the n most frequent n-grams as columns and the titles as rows.\n",
    "\n",
    "    :param ngram: the n-gram to use. Can be 'unigram', 'bigram', or 'trigram'\n",
    "    :return: a count matrix. The columns are the n-grams, the rows are the titles.\n",
    "    \"\"\"\n",
    "    assert ngram in ['unigrams', 'bigrams', 'trigrams', \"all_grams\"]\n",
    "    mfw = get_most_frequent(df[ngram], 1700)\n",
    "    arr = np.zeros([17, 1700])\n",
    "    for doc_idx, doc in df.iterrows():\n",
    "        mfw_doc = doc[ngram]\n",
    "        for w_idx, (_, words) in enumerate(mfw):\n",
    "            count = mfw_doc[words] if words in mfw_doc else 0\n",
    "            arr[doc_idx][w_idx] = count\n",
    "    words_ls = [words for _, words in mfw]\n",
    "    return pd.DataFrame(arr, columns=words_ls, index=df['title'])\n",
    "\n",
    "\n",
    "X_raw = get_count_matrix()\n",
    "X_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def tf(term: Tuple[str, ...], document: str, X_raw: pd.DataFrame, all_data: pd.DataFrame, ngram: str) -> float:\n",
    "    \"\"\"Calculates the term frequency of a term in a document.\n",
    "\n",
    "    The term frequency is calculated as the number of times the term appears in the document divided by the number of words in the document.\n",
    "\n",
    "    :param term: the term to calculate the frequency of, e.g. ('word1', 'word2')\n",
    "    :param document: the title of the document to calculate the frequency in\n",
    "    :param X_raw: the raw count matrix\n",
    "    :param all_data: the dataframe containing all the data\n",
    "    :param ngram: e.g. 'unigrams'\n",
    "    :return: the term frequency\n",
    "    \"\"\"\n",
    "    assert ngram in ['unigrams', 'bigrams', 'trigrams', 'all_grams']\n",
    "    numerator = X_raw.loc[document][term]\n",
    "    terms: dict = all_data.loc[all_data['title'] == document][ngram].values[0]\n",
    "    denominator = len(terms)\n",
    "    return numerator / denominator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def idf(term: Tuple[str, ...], all_data: pd.DataFrame) -> float:\n",
    "    \"\"\"Calculates the inverse document frequency of a term\n",
    "\n",
    "    :param term: the term to calculate the frequency of\n",
    "    :param all_data: the dataframe containing all the data\n",
    "    :return: the inverse document frequency of the term\n",
    "    \"\"\"\n",
    "    total_documents = all_data.shape[0]\n",
    "    has_term = all_data['all_grams'].map(lambda x: 1 if term in x else 0)\n",
    "    docs_with_term = has_term.aggregate(sum)\n",
    "    return np.log(total_documents / docs_with_term) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def tf_idf(term: Tuple[str, ...], document: str, X_raw: pd.DataFrame, all_data: pd.DataFrame) -> float:\n",
    "    \"\"\"Calculates the tf-idf score of a term in a document.\n",
    "\n",
    "    :param term: the term to calculate the frequency of\n",
    "    :param document: the title of the document to calculate the frequency in\n",
    "    :param X_raw: the raw count matrix\n",
    "    :param all_data: the dataframe containing all the data\n",
    "    :return: the tf-idf score of the term in the document\n",
    "    \"\"\"\n",
    "    return (np.log(1 + X_raw.loc[document][term])) * idf(term, all_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    (behavior,)  (analysis,)  \\\ntitle                                                                          \nAnomaly Detection at Multiple Scales                   0.000000     0.827726   \nBehavioral analytics                                  11.215445     4.100716   \nBusiness analytics                                     0.000000     4.806898   \nCORE (research service)                                0.000000     0.827726   \nDaisy Intelligence                                     0.000000     0.827726   \nData Applied                                           0.000000     1.311914   \nData mining in agriculture                             0.000000     1.311914   \nData thinking                                          0.000000     1.921920   \nDocument processing                                    0.000000     0.827726   \nEquifax Workforce Solutions                            0.000000     0.000000   \nGame analytics                                         0.000000     0.827726   \nInference attack                                       1.541404     0.000000   \nPath analysis (computing)                              2.443067     3.843840   \nAutomatic number-plate recognition in the Unite...     1.541404     0.827726   \nPRODIGAL (computer system)                             2.443067     1.655452   \nText mining                                            0.000000     4.100716   \nZapaday                                                0.000000     0.000000   \n\n                                                     (data,)  (business,)  \\\ntitle                                                                       \nAnomaly Detection at Multiple Scales                0.779904     0.000000   \nBehavioral analytics                                1.236118     1.133981   \nBusiness analytics                                  2.189466     7.872680   \nCORE (research service)                             2.590784     0.000000   \nDaisy Intelligence                                  0.779904     0.000000   \nData Applied                                        2.189466     1.133981   \nData mining in agriculture                          3.370688     0.000000   \nData thinking                                       3.899518     2.931298   \nDocument processing                                 2.590784     1.797317   \nEquifax Workforce Solutions                         0.000000     2.633022   \nGame analytics                                      1.236118     1.133981   \nInference attack                                    2.189466     0.000000   \nPath analysis (computing)                           2.189466     1.797317   \nAutomatic number-plate recognition in the Unite...  3.665890     0.000000   \nPRODIGAL (computer system)                          1.810880     0.000000   \nText mining                                         3.575829     3.922930   \nZapaday                                             0.000000     0.000000   \n\n                                                     (also,)   (text,)  \\\ntitle                                                                    \nAnomaly Detection at Multiple Scales                0.000000  0.000000   \nBehavioral analytics                                4.179991  0.000000   \nBusiness analytics                                  2.786661  0.000000   \nCORE (research service)                             1.758187  4.245084   \nDaisy Intelligence                                  0.879094  0.000000   \nData Applied                                        0.000000  0.000000   \nData mining in agriculture                          2.272424  0.000000   \nData thinking                                       2.041192  0.000000   \nDocument processing                                 3.151518  3.972486   \nEquifax Workforce Solutions                         2.467928  0.000000   \nGame analytics                                      0.000000  0.000000   \nInference attack                                    1.393330  0.000000   \nPath analysis (computing)                           1.758187  1.415028   \nAutomatic number-plate recognition in the Unite...  4.082384  1.415028   \nPRODIGAL (computer system)                          0.000000  1.415028   \nText mining                                         2.920286  9.116945   \nZapaday                                             0.879094  0.000000   \n\n                                                      (anpr,)    (use,)  \\\ntitle                                                                     \nAnomaly Detection at Multiple Scales                 0.000000  0.000000   \nBehavioral analytics                                 0.000000  3.670286   \nBusiness analytics                                   0.000000  2.121901   \nCORE (research service)                              0.000000  2.463451   \nDaisy Intelligence                                   0.000000  0.000000   \nData Applied                                         0.000000  0.000000   \nData mining in agriculture                           0.000000  2.978465   \nData thinking                                        0.000000  2.121901   \nDocument processing                                  0.000000  2.463451   \nEquifax Workforce Solutions                          0.000000  0.000000   \nGame analytics                                       0.000000  0.000000   \nInference attack                                     0.000000  0.000000   \nPath analysis (computing)                            0.000000  1.060951   \nAutomatic number-plate recognition in the Unite...  17.118779  5.720983   \nPRODIGAL (computer system)                           0.000000  0.000000   \nText mining                                          0.000000  3.803468   \nZapaday                                              0.000000  1.681567   \n\n                                                     (used,)  (plate,)  ...  \\\ntitle                                                                   ...   \nAnomaly Detection at Multiple Scales                0.000000   0.00000  ...   \nBehavioral analytics                                3.922930   0.00000  ...   \nBusiness analytics                                  4.317468   0.00000  ...   \nCORE (research service)                             1.133981   0.00000  ...   \nDaisy Intelligence                                  0.000000   0.00000  ...   \nData Applied                                        0.000000   0.00000  ...   \nData mining in agriculture                          3.767003   0.00000  ...   \nData thinking                                       0.000000   0.00000  ...   \nDocument processing                                 3.183487   0.00000  ...   \nEquifax Workforce Solutions                         0.000000   0.00000  ...   \nGame analytics                                      1.133981   0.00000  ...   \nInference attack                                    1.133981   0.00000  ...   \nPath analysis (computing)                           0.000000   0.00000  ...   \nAutomatic number-plate recognition in the Unite...  5.720247  17.02963  ...   \nPRODIGAL (computer system)                          0.000000   0.00000  ...   \nText mining                                         4.065279   0.00000  ...   \nZapaday                                             0.000000   0.00000  ...   \n\n                                                    (defense,)  (dedicated,)  \\\ntitle                                                                          \nAnomaly Detection at Multiple Scales                  0.000000      0.000000   \nBehavioral analytics                                  0.000000      0.000000   \nBusiness analytics                                    0.000000      0.000000   \nCORE (research service)                               0.000000      0.000000   \nDaisy Intelligence                                    0.000000      0.000000   \nData Applied                                          0.000000      0.000000   \nData mining in agriculture                            0.000000      0.000000   \nData thinking                                         0.000000      0.000000   \nDocument processing                                   0.000000      0.000000   \nEquifax Workforce Solutions                           0.000000      0.000000   \nGame analytics                                        0.000000      0.000000   \nInference attack                                      0.000000      0.000000   \nPath analysis (computing)                             0.000000      0.000000   \nAutomatic number-plate recognition in the Unite...    2.176528      5.313962   \nPRODIGAL (computer system)                            3.449715      0.000000   \nText mining                                           0.000000      0.000000   \nZapaday                                               0.000000      0.000000   \n\n                                                    (decades,)  (decade,)  \\\ntitle                                                                       \nAnomaly Detection at Multiple Scales                  0.000000   0.000000   \nBehavioral analytics                                  1.895481   2.176528   \nBusiness analytics                                    0.000000   0.000000   \nCORE (research service)                               0.000000   0.000000   \nDaisy Intelligence                                    0.000000   0.000000   \nData Applied                                          0.000000   0.000000   \nData mining in agriculture                            1.895481   0.000000   \nData thinking                                         0.000000   0.000000   \nDocument processing                                   0.000000   0.000000   \nEquifax Workforce Solutions                           0.000000   0.000000   \nGame analytics                                        0.000000   0.000000   \nInference attack                                      0.000000   0.000000   \nPath analysis (computing)                             0.000000   0.000000   \nAutomatic number-plate recognition in the Unite...    0.000000   0.000000   \nPRODIGAL (computer system)                            0.000000   0.000000   \nText mining                                           1.895481   3.449715   \nZapaday                                               0.000000   0.000000   \n\n                                                      (dbt,)  (dataset,)  \\\ntitle                                                                      \nAnomaly Detection at Multiple Scales                0.000000    0.000000   \nBehavioral analytics                                5.313962    0.000000   \nBusiness analytics                                  0.000000    0.000000   \nCORE (research service)                             0.000000    2.176528   \nDaisy Intelligence                                  0.000000    0.000000   \nData Applied                                        0.000000    0.000000   \nData mining in agriculture                          0.000000    0.000000   \nData thinking                                       0.000000    0.000000   \nDocument processing                                 0.000000    0.000000   \nEquifax Workforce Solutions                         0.000000    0.000000   \nGame analytics                                      0.000000    0.000000   \nInference attack                                    0.000000    0.000000   \nPath analysis (computing)                           0.000000    0.000000   \nAutomatic number-plate recognition in the Unite...  0.000000    3.449715   \nPRODIGAL (computer system)                          0.000000    0.000000   \nText mining                                         0.000000    0.000000   \nZapaday                                             0.000000    0.000000   \n\n                                                    (data, science)  \\\ntitle                                                                 \nAnomaly Detection at Multiple Scales                       0.000000   \nBehavioral analytics                                       0.000000   \nBusiness analytics                                         0.000000   \nCORE (research service)                                    0.000000   \nDaisy Intelligence                                         0.000000   \nData Applied                                               0.000000   \nData mining in agriculture                                 0.000000   \nData thinking                                              5.313962   \nDocument processing                                        0.000000   \nEquifax Workforce Solutions                                0.000000   \nGame analytics                                             0.000000   \nInference attack                                           0.000000   \nPath analysis (computing)                                  0.000000   \nAutomatic number-plate recognition in the Unite...         0.000000   \nPRODIGAL (computer system)                                 0.000000   \nText mining                                                0.000000   \nZapaday                                                    0.000000   \n\n                                                    (data, mining, techniques)  \\\ntitle                                                                            \nAnomaly Detection at Multiple Scales                                  0.000000   \nBehavioral analytics                                                  0.000000   \nBusiness analytics                                                    0.000000   \nCORE (research service)                                               0.000000   \nDaisy Intelligence                                                    0.000000   \nData Applied                                                          0.000000   \nData mining in agriculture                                            3.449715   \nData thinking                                                         0.000000   \nDocument processing                                                   0.000000   \nEquifax Workforce Solutions                                           0.000000   \nGame analytics                                                        0.000000   \nInference attack                                                      0.000000   \nPath analysis (computing)                                             0.000000   \nAutomatic number-plate recognition in the Unite...                    0.000000   \nPRODIGAL (computer system)                                            0.000000   \nText mining                                                           2.176528   \nZapaday                                                               0.000000   \n\n                                                    (data, entry)  \\\ntitle                                                               \nAnomaly Detection at Multiple Scales                     0.000000   \nBehavioral analytics                                     0.000000   \nBusiness analytics                                       0.000000   \nCORE (research service)                                  0.000000   \nDaisy Intelligence                                       0.000000   \nData Applied                                             0.000000   \nData mining in agriculture                               0.000000   \nData thinking                                            0.000000   \nDocument processing                                      5.313962   \nEquifax Workforce Solutions                              0.000000   \nGame analytics                                           0.000000   \nInference attack                                         0.000000   \nPath analysis (computing)                                0.000000   \nAutomatic number-plate recognition in the Unite...       0.000000   \nPRODIGAL (computer system)                               0.000000   \nText mining                                              0.000000   \nZapaday                                                  0.000000   \n\n                                                    (data, centre)  \ntitle                                                               \nAnomaly Detection at Multiple Scales                      0.000000  \nBehavioral analytics                                      0.000000  \nBusiness analytics                                        0.000000  \nCORE (research service)                                   0.000000  \nDaisy Intelligence                                        0.000000  \nData Applied                                              0.000000  \nData mining in agriculture                                0.000000  \nData thinking                                             0.000000  \nDocument processing                                       0.000000  \nEquifax Workforce Solutions                               0.000000  \nGame analytics                                            0.000000  \nInference attack                                          0.000000  \nPath analysis (computing)                                 0.000000  \nAutomatic number-plate recognition in the Unite...        5.313962  \nPRODIGAL (computer system)                                0.000000  \nText mining                                               0.000000  \nZapaday                                                   0.000000  \n\n[17 rows x 1700 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>(behavior,)</th>\n      <th>(analysis,)</th>\n      <th>(data,)</th>\n      <th>(business,)</th>\n      <th>(also,)</th>\n      <th>(text,)</th>\n      <th>(anpr,)</th>\n      <th>(use,)</th>\n      <th>(used,)</th>\n      <th>(plate,)</th>\n      <th>...</th>\n      <th>(defense,)</th>\n      <th>(dedicated,)</th>\n      <th>(decades,)</th>\n      <th>(decade,)</th>\n      <th>(dbt,)</th>\n      <th>(dataset,)</th>\n      <th>(data, science)</th>\n      <th>(data, mining, techniques)</th>\n      <th>(data, entry)</th>\n      <th>(data, centre)</th>\n    </tr>\n    <tr>\n      <th>title</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Anomaly Detection at Multiple Scales</th>\n      <td>0.000000</td>\n      <td>0.827726</td>\n      <td>0.779904</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Behavioral analytics</th>\n      <td>11.215445</td>\n      <td>4.100716</td>\n      <td>1.236118</td>\n      <td>1.133981</td>\n      <td>4.179991</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.670286</td>\n      <td>3.922930</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.895481</td>\n      <td>2.176528</td>\n      <td>5.313962</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Business analytics</th>\n      <td>0.000000</td>\n      <td>4.806898</td>\n      <td>2.189466</td>\n      <td>7.872680</td>\n      <td>2.786661</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.121901</td>\n      <td>4.317468</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>CORE (research service)</th>\n      <td>0.000000</td>\n      <td>0.827726</td>\n      <td>2.590784</td>\n      <td>0.000000</td>\n      <td>1.758187</td>\n      <td>4.245084</td>\n      <td>0.000000</td>\n      <td>2.463451</td>\n      <td>1.133981</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.176528</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Daisy Intelligence</th>\n      <td>0.000000</td>\n      <td>0.827726</td>\n      <td>0.779904</td>\n      <td>0.000000</td>\n      <td>0.879094</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Data Applied</th>\n      <td>0.000000</td>\n      <td>1.311914</td>\n      <td>2.189466</td>\n      <td>1.133981</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Data mining in agriculture</th>\n      <td>0.000000</td>\n      <td>1.311914</td>\n      <td>3.370688</td>\n      <td>0.000000</td>\n      <td>2.272424</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.978465</td>\n      <td>3.767003</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.895481</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.449715</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Data thinking</th>\n      <td>0.000000</td>\n      <td>1.921920</td>\n      <td>3.899518</td>\n      <td>2.931298</td>\n      <td>2.041192</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.121901</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.313962</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Document processing</th>\n      <td>0.000000</td>\n      <td>0.827726</td>\n      <td>2.590784</td>\n      <td>1.797317</td>\n      <td>3.151518</td>\n      <td>3.972486</td>\n      <td>0.000000</td>\n      <td>2.463451</td>\n      <td>3.183487</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.313962</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Equifax Workforce Solutions</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.633022</td>\n      <td>2.467928</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Game analytics</th>\n      <td>0.000000</td>\n      <td>0.827726</td>\n      <td>1.236118</td>\n      <td>1.133981</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.133981</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Inference attack</th>\n      <td>1.541404</td>\n      <td>0.000000</td>\n      <td>2.189466</td>\n      <td>0.000000</td>\n      <td>1.393330</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.133981</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Path analysis (computing)</th>\n      <td>2.443067</td>\n      <td>3.843840</td>\n      <td>2.189466</td>\n      <td>1.797317</td>\n      <td>1.758187</td>\n      <td>1.415028</td>\n      <td>0.000000</td>\n      <td>1.060951</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Automatic number-plate recognition in the United Kingdom</th>\n      <td>1.541404</td>\n      <td>0.827726</td>\n      <td>3.665890</td>\n      <td>0.000000</td>\n      <td>4.082384</td>\n      <td>1.415028</td>\n      <td>17.118779</td>\n      <td>5.720983</td>\n      <td>5.720247</td>\n      <td>17.02963</td>\n      <td>...</td>\n      <td>2.176528</td>\n      <td>5.313962</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.449715</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.313962</td>\n    </tr>\n    <tr>\n      <th>PRODIGAL (computer system)</th>\n      <td>2.443067</td>\n      <td>1.655452</td>\n      <td>1.810880</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.415028</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>3.449715</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Text mining</th>\n      <td>0.000000</td>\n      <td>4.100716</td>\n      <td>3.575829</td>\n      <td>3.922930</td>\n      <td>2.920286</td>\n      <td>9.116945</td>\n      <td>0.000000</td>\n      <td>3.803468</td>\n      <td>4.065279</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.895481</td>\n      <td>3.449715</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.176528</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Zapaday</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.879094</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.681567</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17 rows × 1700 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tfidf_matrix(ngram: str = \"all_grams\") -> pd.DataFrame:\n",
    "    \"\"\"Returns a raw count matrix for the given n-gram.\n",
    "\n",
    "    The matrix should contain the n most frequent n-grams as columns and the titles as rows.\n",
    "\n",
    "    :param ngram: the n-gram to use. Can be 'unigram', 'bigram', or 'trigram'\n",
    "    :return: a count matrix. The columns are the n-grams, the rows are the titles.\n",
    "    \"\"\"\n",
    "    assert ngram in ['unigrams', 'bigrams', 'trigrams', \"all_grams\"]\n",
    "    mfw = get_most_frequent(df[ngram], 1700)\n",
    "    arr = np.zeros([17, 1700])\n",
    "    # Documents / Articles\n",
    "    for doc_idx, doc in df.iterrows():\n",
    "        # Most frequent words - {('girvan',): 1, ('operates',): 2, ('aclu',): 7, ...}\n",
    "        mfw_doc = doc[ngram]\n",
    "        for w_idx, (word_freq, word) in enumerate(mfw):\n",
    "            arr[doc_idx][w_idx] = tf_idf(term=word, document=doc['title'], X_raw=X_raw, all_data=df)\n",
    "    words_ls = [words for _, words in mfw]\n",
    "    return pd.DataFrame(arr, columns=words_ls, index=df['title'])\n",
    "\n",
    "\n",
    "X_tfidf = get_tfidf_matrix()\n",
    "X_tfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "c) Using SVD, decompose and truncate your numerical features $X = U \\Sigma V^\\top$ into ($docs \\times topics$) and ($topics \\times terms$) matrices (left/right singular vectors, respectively) using $6$ topics. List $5$ most significant $n$-grams for each topic, measured by values of the ($topics \\times terms$) matrix. Do this for both features $X_\\mathrm{raw}$ and $X_\\mathrm{tf-idf}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_left_right_svd(X):\n",
    "    \"\"\"Performs SVD and truncation.\n",
    "    Returns the left and right singular vectors for matrix X.\n",
    "\n",
    "    :param X: matrix (raw n-gram count or tf-idf) of size (docs, terms)\n",
    "    :return left: left singular vector of X, size (docs, topics)\n",
    "    :return right: right singular vector of X, size (topics, terms)\n",
    "    \"\"\"\n",
    "    svd = TruncatedSVD(n_components=6, random_state=42)\n",
    "    # left singular vectors. (docs x topics)\n",
    "    left = svd.fit_transform(X)\n",
    "    # right singular vectors. (topics x terms)\n",
    "    right = svd.components_\n",
    "\n",
    "    return left, right"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_top5_ngrams_svd(X):\n",
    "    \"\"\"\n",
    "    Returns top 5 most significant n-grams for the 6 topics.\n",
    "\n",
    "    :param X: matrix (raw n-gram count or tf-idf) of size (docs, terms)\n",
    "    :return top5: list of lists. For every topic (6) returns the top 5 most\n",
    "        significant n-grams based on X's SVD.\n",
    "    \"\"\"\n",
    "    # perform SVD\n",
    "    left, right = get_left_right_svd(X)\n",
    "\n",
    "    # create Pandas df of the right vector\n",
    "    right_df = pd.DataFrame(right.copy(), columns=X_raw.columns)\n",
    "\n",
    "    # temp value for getting the top5\n",
    "    min = -99\n",
    "    # 6 empty lists\n",
    "    top5 = [[] for i in range(len(right_df))]\n",
    "    for i in range(5):\n",
    "        # argmax for topics\n",
    "        ids = right_df.idxmax(axis=1)\n",
    "        # putting negative values for the max values so we don't get the same values again as max\n",
    "        for j, idx in enumerate(ids):\n",
    "            right_df[idx][j] = min\n",
    "\n",
    "        # inverting the ids list so we have topic[]=[n-grams], instead of top[]=[ngram-topic1, ngram-topic2...]\n",
    "        for j in range(len(right_df)):\n",
    "            top5[j].append(ids[j])\n",
    "\n",
    "    print('Top 5 n-grams for every topic:')\n",
    "    for i in range(len(right_df)):\n",
    "        print(f'Topic {i+1}: {top5[i]}')\n",
    "\n",
    "    return top5\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# get top 5 most significant words per topics\n",
    "# raw n-gram counts\n",
    "print('Raw n-gram counts:')\n",
    "top5_raw = get_top5_ngrams_svd(X_raw)"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw n-gram counts:\n",
      "Top 5 n-grams for every topic:\n",
      "Topic 1: [('anpr',), ('plate',), ('behavior',), ('license',), ('system',)]\n",
      "Topic 2: [('behavior',), ('behaviorism',), ('skinner',), ('analysis',), ('stimulus',)]\n",
      "Topic 3: [('business',), ('analysis',), ('requirements',), ('business', 'analysis'), ('text',)]\n",
      "Topic 4: [('text',), ('mining',), ('text', 'mining'), ('data',), ('information',)]\n",
      "Topic 5: [('access',), ('core',), ('open',), ('open', 'access'), ('content',)]\n",
      "Topic 6: [('document',), ('processing',), ('data',), ('document', 'processing'), ('also',)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf n-gram counts:\n",
      "Top 5 n-grams for every topic:\n",
      "Topic 1: [('anpr',), ('plate',), ('cameras',), ('license', 'plate'), ('plates',)]\n",
      "Topic 2: [('behaviorism',), ('skinner',), ('stimulus',), ('conditioning',), ('cognitive',)]\n",
      "Topic 3: [('business', 'analysis'), ('business', 'analysts'), ('business',), ('business', 'analyst'), ('costs',)]\n",
      "Topic 4: [('text', 'mining'), ('text',), ('text', 'analytics'), ('copyright',), ('sentiment',)]\n",
      "Topic 5: [('agriculture',), ('fruit',), ('pesticide',), ('defects',), ('cotton',)]\n",
      "Topic 6: [('talx',), ('sec',), ('cohen',), ('inc',), ('equifax',)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get top 5 most significant words per topics\n",
    "# raw n-gram counts\n",
    "print('tf-idf n-gram counts:')\n",
    "top5_tfidf = get_top5_ngrams_svd(X_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (3279414177.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [24]\u001B[1;36m\u001B[0m\n\u001B[1;33m    d) Compare and comment the results with respect to the selection of features and the $n$ value in $n$-grams.\u001B[0m\n\u001B[1;37m     ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m unmatched ')'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The format of tf-idf you need to use:**\n",
    "\n",
    "$$ f(tf, idf) = (1 + \\ln (tf)) \\cdot idf $$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ tf = \\frac{number\\ of\\ times\\ term\\ w\\ appears\\ in\\ a\\ document}{total\\ number\\ of\\ terms\\ in\\ that\\ document} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ idf = \\ln(\\frac{total\\ number\\ of\\ documents}{number\\ of\\ documents\\ with\\ term\\ w\\ in\\ them + 1} + 1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1325539b70dd929b003b9ae49f918636dd68cee4cf6191e7ab5acbfab5f97287"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}